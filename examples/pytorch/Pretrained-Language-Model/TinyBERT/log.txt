06/29 06:09:41 AM The args: Namespace(act='gelu', aug_train=False, cache_dir='', data_dir='./glue_data/MNLI', data_url='', do_eval=False, do_lower_case=True, eval_batch_size=32, eval_step=200, gradient_accumulation_steps=1, learning_rate=5e-05, max_seq_length=128, no_cuda=False, num_train_epochs=10.0, output_dir='tmp_ours2', pred_distill=False, seed=42, softmax_act='softmax', student_model='./TinyBERT_General_4L_312D_custom', task_name='MNLI', teacher_model='./checkpoint-36500', temperature=1.0, train_batch_size=32, warmup_proportion=0.1, weight_decay=0.0001)
06/29 06:09:41 AM device: cuda n_gpu: 2
06/29 06:09:48 AM Writing example 0 of 392702
06/29 06:09:48 AM *** Example ***
06/29 06:09:48 AM guid: train-0
06/29 06:09:48 AM tokens: [CLS] conceptual ##ly cream ski ##mming has two basic dimensions - product and geography . [SEP] product and geography are what make cream ski ##mming work . [SEP]
06/29 06:09:48 AM input_ids: 101 17158 2135 6949 8301 25057 2038 2048 3937 9646 1011 4031 1998 10505 1012 102 4031 1998 10505 2024 2054 2191 6949 8301 25057 2147 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/29 06:09:48 AM input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/29 06:09:48 AM segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/29 06:09:48 AM label: neutral
06/29 06:09:48 AM label_id: 1
06/29 06:09:54 AM Writing example 10000 of 392702
06/29 06:10:00 AM Writing example 20000 of 392702
06/29 06:10:06 AM Writing example 30000 of 392702
06/29 06:10:12 AM Writing example 40000 of 392702
06/29 06:10:18 AM Writing example 50000 of 392702
06/29 06:10:23 AM Writing example 60000 of 392702
06/29 06:10:29 AM Writing example 70000 of 392702
06/29 06:10:35 AM Writing example 80000 of 392702
06/29 06:10:41 AM Writing example 90000 of 392702
06/29 06:10:47 AM Writing example 100000 of 392702
06/29 06:10:53 AM Writing example 110000 of 392702
06/29 06:10:59 AM Writing example 120000 of 392702
06/29 06:11:05 AM Writing example 130000 of 392702
06/29 06:11:11 AM Writing example 140000 of 392702
06/29 06:11:17 AM Writing example 150000 of 392702
06/29 06:11:23 AM Writing example 160000 of 392702
06/29 06:11:29 AM Writing example 170000 of 392702
06/29 06:11:35 AM Writing example 180000 of 392702
06/29 06:11:40 AM Writing example 190000 of 392702
06/29 06:11:47 AM Writing example 200000 of 392702
06/29 06:11:53 AM Writing example 210000 of 392702
06/29 06:11:59 AM Writing example 220000 of 392702
06/29 06:12:05 AM Writing example 230000 of 392702
06/29 06:12:10 AM Writing example 240000 of 392702
06/29 06:12:16 AM Writing example 250000 of 392702
06/29 06:12:22 AM Writing example 260000 of 392702
06/29 06:12:28 AM Writing example 270000 of 392702
06/29 06:12:35 AM Writing example 280000 of 392702
06/29 06:12:41 AM Writing example 290000 of 392702
06/29 06:12:47 AM Writing example 300000 of 392702
06/29 06:12:52 AM Writing example 310000 of 392702
06/29 06:12:58 AM Writing example 320000 of 392702
06/29 06:13:04 AM Writing example 330000 of 392702
06/29 06:13:10 AM Writing example 340000 of 392702
06/29 06:13:16 AM Writing example 350000 of 392702
06/29 06:13:22 AM Writing example 360000 of 392702
06/29 06:13:29 AM Writing example 370000 of 392702
06/29 06:13:35 AM Writing example 380000 of 392702
06/29 06:13:41 AM Writing example 390000 of 392702
06/29 06:13:46 AM Writing example 0 of 9815
06/29 06:13:46 AM *** Example ***
06/29 06:13:46 AM guid: dev_matched-0
06/29 06:13:46 AM tokens: [CLS] the new rights are nice enough [SEP] everyone really likes the newest benefits [SEP]
06/29 06:13:46 AM input_ids: 101 1996 2047 2916 2024 3835 2438 102 3071 2428 7777 1996 14751 6666 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/29 06:13:46 AM input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/29 06:13:46 AM segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
06/29 06:13:46 AM label: neutral
06/29 06:13:46 AM label_id: 1
06/29 06:13:52 AM Model config {
  "_name_or_path": "bert-base-uncased",
  "architectures": [
    "BertForSequenceClassification"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "crypten": false,
  "finetuning_task": "mnli",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "entailment",
    "1": "neutral",
    "2": "contradiction"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "contradiction": 2,
    "entailment": 0,
    "neutral": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "pre_trained": "",
  "problem_type": "single_label_classification",
  "softmax_act": "softmax",
  "torch_dtype": "float32",
  "training": "",
  "transformers_version": "4.20.0.dev0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

using softmax_act: <function softmax at 0x7fe1575fff28>
using act: <function gelu at 0x7fe11eb769d8>
using softmax_act: <function softmax at 0x7fe1575fff28>
using act: <function gelu at 0x7fe11eb769d8>
using softmax_act: <function softmax at 0x7fe1575fff28>
using act: <function gelu at 0x7fe11eb769d8>
using softmax_act: <function softmax at 0x7fe1575fff28>
using act: <function gelu at 0x7fe11eb769d8>
using softmax_act: <function softmax at 0x7fe1575fff28>
using act: <function gelu at 0x7fe11eb769d8>
using softmax_act: <function softmax at 0x7fe1575fff28>
using act: <function gelu at 0x7fe11eb769d8>
using softmax_act: <function softmax at 0x7fe1575fff28>
using act: <function gelu at 0x7fe11eb769d8>
using softmax_act: <function softmax at 0x7fe1575fff28>
using act: <function gelu at 0x7fe11eb769d8>
using softmax_act: <function softmax at 0x7fe1575fff28>
using act: <function gelu at 0x7fe11eb769d8>
using softmax_act: <function softmax at 0x7fe1575fff28>
using act: <function gelu at 0x7fe11eb769d8>
using softmax_act: <function softmax at 0x7fe1575fff28>
using act: <function gelu at 0x7fe11eb769d8>
using softmax_act: <function softmax at 0x7fe1575fff28>
using act: <function gelu at 0x7fe11eb769d8>
06/29 06:13:55 AM Loading model ./checkpoint-36500/pytorch_model.bin
./checkpoint-36500/pytorch_model.bin
06/29 06:13:55 AM loading model...
06/29 06:13:55 AM done!
06/29 06:13:55 AM Weights of TinyBertForSequenceClassification not initialized from pretrained model: ['fit_dense.weight', 'fit_dense.bias']
06/29 06:13:55 AM Weights from pretrained model not used in TinyBertForSequenceClassification: ['bert.embeddings.position_ids']
06/29 06:14:26 AM ***** Teacher evaluation *****
06/29 06:14:26 AM {'acc': 0.8398369842078451, 'eval_loss': 0.4336751479085183}
06/29 06:14:26 AM Model config {
  "attention_probs_dropout_prob": 0.1,
  "cell": {},
  "emb_size": 312,
  "hidden_act": "quad",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 312,
  "initializer_range": 0.02,
  "intermediate_size": 1200,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 4,
  "pre_trained": "",
  "softmax_act": "2relu",
  "structure": [],
  "training": "",
  "type_vocab_size": 2,
  "vocab_size": 30522
}

using softmax_act: <function softmax_2relu at 0x7fe11eb76b70>
using act: <function quad at 0x7fe11eb76ae8>
using softmax_act: <function softmax_2relu at 0x7fe11eb76b70>
using act: <function quad at 0x7fe11eb76ae8>
using softmax_act: <function softmax_2relu at 0x7fe11eb76b70>
using act: <function quad at 0x7fe11eb76ae8>
using softmax_act: <function softmax_2relu at 0x7fe11eb76b70>
using act: <function quad at 0x7fe11eb76ae8>
06/29 06:14:27 AM Loading model ./TinyBERT_General_4L_312D_custom/pytorch_model.bin
./TinyBERT_General_4L_312D_custom/pytorch_model.bin
06/29 06:14:27 AM loading model...
06/29 06:14:27 AM done!
06/29 06:14:27 AM Weights of TinyBertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias', 'fit_dense.weight', 'fit_dense.bias']
06/29 06:14:27 AM Weights from pretrained model not used in TinyBertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'fit_denses.0.weight', 'fit_denses.0.bias', 'fit_denses.1.weight', 'fit_denses.1.bias', 'fit_denses.2.weight', 'fit_denses.2.bias', 'fit_denses.3.weight', 'fit_denses.3.bias', 'fit_denses.4.weight', 'fit_denses.4.bias']
06/29 06:14:27 AM ***** Running training *****
06/29 06:14:27 AM   Num examples = 392702
06/29 06:14:27 AM   Batch size = 32
06/29 06:14:27 AM   Num steps = 122710
06/29 06:14:27 AM n: module.bert.embeddings.word_embeddings.weight
06/29 06:14:27 AM n: module.bert.embeddings.position_embeddings.weight
06/29 06:14:27 AM n: module.bert.embeddings.token_type_embeddings.weight
06/29 06:14:27 AM n: module.bert.embeddings.LayerNorm.weight
06/29 06:14:27 AM n: module.bert.embeddings.LayerNorm.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.0.attention.self.query.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.0.attention.self.query.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.0.attention.self.key.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.0.attention.self.key.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.0.attention.self.value.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.0.attention.self.value.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.0.attention.output.dense.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.0.attention.output.dense.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.0.attention.output.LayerNorm.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.0.attention.output.LayerNorm.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.0.intermediate.dense.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.0.intermediate.dense.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.0.output.dense.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.0.output.dense.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.0.output.LayerNorm.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.0.output.LayerNorm.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.1.attention.self.query.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.1.attention.self.query.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.1.attention.self.key.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.1.attention.self.key.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.1.attention.self.value.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.1.attention.self.value.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.1.attention.output.dense.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.1.attention.output.dense.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.1.attention.output.LayerNorm.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.1.attention.output.LayerNorm.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.1.intermediate.dense.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.1.intermediate.dense.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.1.output.dense.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.1.output.dense.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.1.output.LayerNorm.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.1.output.LayerNorm.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.2.attention.self.query.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.2.attention.self.query.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.2.attention.self.key.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.2.attention.self.key.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.2.attention.self.value.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.2.attention.self.value.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.2.attention.output.dense.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.2.attention.output.dense.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.2.attention.output.LayerNorm.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.2.attention.output.LayerNorm.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.2.intermediate.dense.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.2.intermediate.dense.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.2.output.dense.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.2.output.dense.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.2.output.LayerNorm.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.2.output.LayerNorm.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.3.attention.self.query.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.3.attention.self.query.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.3.attention.self.key.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.3.attention.self.key.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.3.attention.self.value.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.3.attention.self.value.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.3.attention.output.dense.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.3.attention.output.dense.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.3.attention.output.LayerNorm.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.3.attention.output.LayerNorm.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.3.intermediate.dense.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.3.intermediate.dense.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.3.output.dense.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.3.output.dense.bias
06/29 06:14:27 AM n: module.bert.encoder.layer.3.output.LayerNorm.weight
06/29 06:14:27 AM n: module.bert.encoder.layer.3.output.LayerNorm.bias
06/29 06:14:27 AM n: module.bert.pooler.dense.weight
06/29 06:14:27 AM n: module.bert.pooler.dense.bias
06/29 06:14:27 AM n: module.classifier.weight
06/29 06:14:27 AM n: module.classifier.bias
06/29 06:14:27 AM n: module.fit_dense.weight
06/29 06:14:27 AM n: module.fit_dense.bias
06/29 06:14:27 AM Total parameters: 14591571
06/29 06:14:58 AM ***** Running evaluation *****
06/29 06:14:58 AM   Epoch = 0 iter 199 step
06/29 06:14:58 AM   Num examples = 9815
06/29 06:14:58 AM   Batch size = 32
06/29 06:14:58 AM ***** Eval results *****
06/29 06:14:58 AM   att_loss = 6.671934997616102
06/29 06:14:58 AM   cls_loss = 0.0
06/29 06:14:58 AM   global_step = 199
06/29 06:14:58 AM   loss = 8.212496330989666
06/29 06:14:58 AM   rep_loss = 1.5405613279821884
06/29 06:14:58 AM ***** Save model *****
06/29 06:15:24 AM ***** Running evaluation *****
06/29 06:15:24 AM   Epoch = 0 iter 399 step
06/29 06:15:24 AM   Num examples = 9815
06/29 06:15:24 AM   Batch size = 32
06/29 06:15:24 AM ***** Eval results *****
06/29 06:15:24 AM   att_loss = 5.807368531262965
06/29 06:15:24 AM   cls_loss = 0.0
06/29 06:15:24 AM   global_step = 399
06/29 06:15:24 AM   loss = 7.227576261773743
06/29 06:15:24 AM   rep_loss = 1.4202077314070891
06/29 06:15:24 AM ***** Save model *****
06/29 06:15:52 AM ***** Running evaluation *****
06/29 06:15:52 AM   Epoch = 0 iter 599 step
06/29 06:15:52 AM   Num examples = 9815
06/29 06:15:52 AM   Batch size = 32
06/29 06:15:52 AM ***** Eval results *****
06/29 06:15:52 AM   att_loss = 5.250845075648694
06/29 06:15:52 AM   cls_loss = 0.0
06/29 06:15:52 AM   global_step = 599
06/29 06:15:52 AM   loss = 6.603551067772612
06/29 06:15:52 AM   rep_loss = 1.3527059905318068
06/29 06:15:52 AM ***** Save model *****
06/29 06:16:18 AM ***** Running evaluation *****
06/29 06:16:18 AM   Epoch = 0 iter 799 step
06/29 06:16:18 AM   Num examples = 9815
06/29 06:16:18 AM   Batch size = 32
06/29 06:16:18 AM ***** Eval results *****
06/29 06:16:18 AM   att_loss = 4.92486464693788
06/29 06:16:18 AM   cls_loss = 0.0
06/29 06:16:18 AM   global_step = 799
06/29 06:16:18 AM   loss = 6.235552651115293
06/29 06:16:18 AM   rep_loss = 1.310688003729819
06/29 06:16:18 AM ***** Save model *****
06/29 06:16:44 AM ***** Running evaluation *****
06/29 06:16:44 AM   Epoch = 0 iter 999 step
06/29 06:16:44 AM   Num examples = 9815
06/29 06:16:44 AM   Batch size = 32
06/29 06:16:44 AM ***** Eval results *****
06/29 06:16:44 AM   att_loss = 4.721977100000009
06/29 06:16:44 AM   cls_loss = 0.0
06/29 06:16:44 AM   global_step = 999
06/29 06:16:44 AM   loss = 6.003203089888747
06/29 06:16:44 AM   rep_loss = 1.2812259897694096
06/29 06:16:44 AM ***** Save model *****
06/29 06:17:13 AM ***** Running evaluation *****
06/29 06:17:13 AM   Epoch = 0 iter 1199 step
06/29 06:17:13 AM   Num examples = 9815
06/29 06:17:13 AM   Batch size = 32
06/29 06:17:13 AM ***** Eval results *****
06/29 06:17:13 AM   att_loss = 4.570319074307808
06/29 06:17:13 AM   cls_loss = 0.0
06/29 06:17:13 AM   global_step = 1199
06/29 06:17:13 AM   loss = 5.828507661222915
06/29 06:17:13 AM   rep_loss = 1.2581885887047368
06/29 06:17:13 AM ***** Save model *****
06/29 06:17:39 AM ***** Running evaluation *****
06/29 06:17:39 AM   Epoch = 0 iter 1399 step
06/29 06:17:39 AM   Num examples = 9815
06/29 06:17:39 AM   Batch size = 32
06/29 06:17:39 AM ***** Eval results *****
06/29 06:17:39 AM   att_loss = 4.464921090158077
06/29 06:17:39 AM   cls_loss = 0.0
06/29 06:17:39 AM   global_step = 1399
06/29 06:17:39 AM   loss = 5.705647468226053
06/29 06:17:39 AM   rep_loss = 1.2407263778975557
06/29 06:17:39 AM ***** Save model *****
06/29 06:18:06 AM ***** Running evaluation *****
06/29 06:18:06 AM   Epoch = 0 iter 1599 step
06/29 06:18:06 AM   Num examples = 9815
06/29 06:18:06 AM   Batch size = 32
06/29 06:18:06 AM ***** Eval results *****
06/29 06:18:06 AM   att_loss = 4.364666236647223
06/29 06:18:06 AM   cls_loss = 0.0
06/29 06:18:06 AM   global_step = 1599
06/29 06:18:06 AM   loss = 5.589704395607906
06/29 06:18:06 AM   rep_loss = 1.225038157767844
06/29 06:18:06 AM ***** Save model *****
06/29 06:18:33 AM ***** Running evaluation *****
06/29 06:18:33 AM   Epoch = 0 iter 1799 step
06/29 06:18:33 AM   Num examples = 9815
06/29 06:18:33 AM   Batch size = 32
06/29 06:18:33 AM ***** Eval results *****
06/29 06:18:33 AM   att_loss = 4.29276840537041
06/29 06:18:33 AM   cls_loss = 0.0
06/29 06:18:33 AM   global_step = 1799
06/29 06:18:33 AM   loss = 5.505208554832454
06/29 06:18:33 AM   rep_loss = 1.2124401500584219
06/29 06:18:33 AM ***** Save model *****
06/29 06:19:02 AM ***** Running evaluation *****
06/29 06:19:02 AM   Epoch = 0 iter 1999 step
06/29 06:19:02 AM   Num examples = 9815
06/29 06:19:02 AM   Batch size = 32
06/29 06:19:02 AM ***** Eval results *****
06/29 06:19:02 AM   att_loss = 4.230820702456903
06/29 06:19:02 AM   cls_loss = 0.0
06/29 06:19:02 AM   global_step = 1999
06/29 06:19:02 AM   loss = 5.4323070198372045
06/29 06:19:02 AM   rep_loss = 1.2014863177381079
06/29 06:19:02 AM ***** Save model *****
06/29 06:19:28 AM ***** Running evaluation *****
06/29 06:19:28 AM   Epoch = 0 iter 2199 step
06/29 06:19:28 AM   Num examples = 9815
06/29 06:19:28 AM   Batch size = 32
06/29 06:19:28 AM ***** Eval results *****
06/29 06:19:28 AM   att_loss = 4.173398960390217
06/29 06:19:28 AM   cls_loss = 0.0
06/29 06:19:28 AM   global_step = 2199
06/29 06:19:28 AM   loss = 5.364978767623138
06/29 06:19:28 AM   rep_loss = 1.1915798070160786
06/29 06:19:28 AM ***** Save model *****
06/29 06:19:55 AM ***** Running evaluation *****
06/29 06:19:55 AM   Epoch = 0 iter 2399 step
06/29 06:19:55 AM   Num examples = 9815
06/29 06:19:55 AM   Batch size = 32
06/29 06:19:55 AM ***** Eval results *****
06/29 06:19:55 AM   att_loss = 4.1184522228074005
06/29 06:19:55 AM   cls_loss = 0.0
06/29 06:19:55 AM   global_step = 2399
06/29 06:19:55 AM   loss = 5.301144208248181
06/29 06:19:55 AM   rep_loss = 1.1826919861861496
06/29 06:19:55 AM ***** Save model *****
06/29 06:20:24 AM ***** Running evaluation *****
06/29 06:20:24 AM   Epoch = 0 iter 2599 step
06/29 06:20:24 AM   Num examples = 9815
06/29 06:20:24 AM   Batch size = 32
06/29 06:20:24 AM ***** Eval results *****
06/29 06:20:24 AM   att_loss = 4.076091708381068
06/29 06:20:24 AM   cls_loss = 0.0
06/29 06:20:24 AM   global_step = 2599
06/29 06:20:24 AM   loss = 5.251246695703798
06/29 06:20:24 AM   rep_loss = 1.175154987781403
06/29 06:20:24 AM ***** Save model *****
06/29 06:20:50 AM ***** Running evaluation *****
06/29 06:20:50 AM   Epoch = 0 iter 2799 step
06/29 06:20:50 AM   Num examples = 9815
06/29 06:20:50 AM   Batch size = 32
06/29 06:20:50 AM ***** Eval results *****
06/29 06:20:50 AM   att_loss = 4.038706883484656
06/29 06:20:50 AM   cls_loss = 0.0
06/29 06:20:50 AM   global_step = 2799
06/29 06:20:50 AM   loss = 5.207030803912791
06/29 06:20:50 AM   rep_loss = 1.1683239205133154
06/29 06:20:50 AM ***** Save model *****
06/29 06:21:17 AM ***** Running evaluation *****
06/29 06:21:17 AM   Epoch = 0 iter 2999 step
06/29 06:21:17 AM   Num examples = 9815
06/29 06:21:17 AM   Batch size = 32
06/29 06:21:17 AM ***** Eval results *****
06/29 06:21:17 AM   att_loss = 4.00396841094668
06/29 06:21:17 AM   cls_loss = 0.0
06/29 06:21:17 AM   global_step = 2999
06/29 06:21:17 AM   loss = 5.166013610486231
06/29 06:21:17 AM   rep_loss = 1.1620452000562966
06/29 06:21:17 AM ***** Save model *****
06/29 06:21:43 AM ***** Running evaluation *****
06/29 06:21:43 AM   Epoch = 0 iter 3199 step
06/29 06:21:43 AM   Num examples = 9815
06/29 06:21:43 AM   Batch size = 32
06/29 06:21:43 AM ***** Eval results *****
06/29 06:21:43 AM   att_loss = 3.97363939543149
06/29 06:21:43 AM   cls_loss = 0.0
06/29 06:21:43 AM   global_step = 3199
06/29 06:21:43 AM   loss = 5.129816317938387
06/29 06:21:43 AM   rep_loss = 1.1561769227304843
06/29 06:21:43 AM ***** Save model *****
06/29 06:22:09 AM ***** Running evaluation *****
06/29 06:22:09 AM   Epoch = 0 iter 3399 step
06/29 06:22:09 AM   Num examples = 9815
06/29 06:22:09 AM   Batch size = 32
06/29 06:22:09 AM ***** Eval results *****
06/29 06:22:09 AM   att_loss = 3.944731994178864
06/29 06:22:09 AM   cls_loss = 0.0
06/29 06:22:09 AM   global_step = 3399
06/29 06:22:09 AM   loss = 5.095371310238839
06/29 06:22:09 AM   rep_loss = 1.1506393158670802
06/29 06:22:09 AM ***** Save model *****
06/29 06:22:38 AM ***** Running evaluation *****
06/29 06:22:38 AM   Epoch = 0 iter 3599 step
06/29 06:22:38 AM   Num examples = 9815
06/29 06:22:38 AM   Batch size = 32
06/29 06:22:38 AM ***** Eval results *****
06/29 06:22:38 AM   att_loss = 3.9144776895596736
06/29 06:22:38 AM   cls_loss = 0.0
06/29 06:22:38 AM   global_step = 3599
06/29 06:22:38 AM   loss = 5.0597080526566565
06/29 06:22:38 AM   rep_loss = 1.145230363212913
06/29 06:22:38 AM ***** Save model *****
06/29 06:23:05 AM ***** Running evaluation *****
06/29 06:23:05 AM   Epoch = 0 iter 3799 step
06/29 06:23:05 AM   Num examples = 9815
06/29 06:23:05 AM   Batch size = 32
06/29 06:23:05 AM ***** Eval results *****
06/29 06:23:05 AM   att_loss = 3.887001620621768
06/29 06:23:05 AM   cls_loss = 0.0
06/29 06:23:05 AM   global_step = 3799
06/29 06:23:05 AM   loss = 5.027135982862363
06/29 06:23:05 AM   rep_loss = 1.140134362162148
06/29 06:23:05 AM ***** Save model *****
06/29 06:23:32 AM ***** Running evaluation *****
06/29 06:23:32 AM   Epoch = 0 iter 3999 step
06/29 06:23:32 AM   Num examples = 9815
06/29 06:23:32 AM   Batch size = 32
06/29 06:23:32 AM ***** Eval results *****
06/29 06:23:32 AM   att_loss = 3.8619913867069022
06/29 06:23:32 AM   cls_loss = 0.0
06/29 06:23:32 AM   global_step = 3999
06/29 06:23:32 AM   loss = 4.997351547276029
06/29 06:23:32 AM   rep_loss = 1.1353601612249413
06/29 06:23:32 AM ***** Save model *****
06/29 06:24:00 AM ***** Running evaluation *****
06/29 06:24:00 AM   Epoch = 0 iter 4199 step
06/29 06:24:00 AM   Num examples = 9815
06/29 06:24:00 AM   Batch size = 32
06/29 06:24:00 AM ***** Eval results *****
06/29 06:24:00 AM   att_loss = 3.8364076635956224
06/29 06:24:00 AM   cls_loss = 0.0
06/29 06:24:00 AM   global_step = 4199
06/29 06:24:00 AM   loss = 4.967069062711966
06/29 06:24:00 AM   rep_loss = 1.1306613995705823
06/29 06:24:00 AM ***** Save model *****
06/29 06:24:27 AM ***** Running evaluation *****
06/29 06:24:27 AM   Epoch = 0 iter 4399 step
06/29 06:24:27 AM   Num examples = 9815
06/29 06:24:27 AM   Batch size = 32
06/29 06:24:27 AM ***** Eval results *****
06/29 06:24:27 AM   att_loss = 3.8157385283368477
06/29 06:24:27 AM   cls_loss = 0.0
06/29 06:24:27 AM   global_step = 4399
06/29 06:24:27 AM   loss = 4.942230134043918
06/29 06:24:27 AM   rep_loss = 1.1264916064116488
06/29 06:24:27 AM ***** Save model *****
06/29 06:24:53 AM ***** Running evaluation *****
06/29 06:24:53 AM   Epoch = 0 iter 4599 step
06/29 06:24:53 AM   Num examples = 9815
06/29 06:24:53 AM   Batch size = 32
06/29 06:24:53 AM ***** Eval results *****
06/29 06:24:53 AM   att_loss = 3.795594126536914
06/29 06:24:53 AM   cls_loss = 0.0
06/29 06:24:53 AM   global_step = 4599
06/29 06:24:53 AM   loss = 4.918067087269679
06/29 06:24:53 AM   rep_loss = 1.12247296201584
06/29 06:24:53 AM ***** Save model *****
06/29 06:25:20 AM ***** Running evaluation *****
06/29 06:25:20 AM   Epoch = 0 iter 4799 step
06/29 06:25:20 AM   Num examples = 9815
06/29 06:25:20 AM   Batch size = 32
06/29 06:25:20 AM ***** Eval results *****
06/29 06:25:20 AM   att_loss = 3.778104220114293
06/29 06:25:20 AM   cls_loss = 0.0
06/29 06:25:20 AM   global_step = 4799
06/29 06:25:20 AM   loss = 4.8968191841389395
06/29 06:25:20 AM   rep_loss = 1.1187149647077588
06/29 06:25:20 AM ***** Save model *****
06/29 06:25:46 AM ***** Running evaluation *****
06/29 06:25:46 AM   Epoch = 0 iter 4999 step
06/29 06:25:46 AM   Num examples = 9815
06/29 06:25:46 AM   Batch size = 32
06/29 06:25:46 AM ***** Eval results *****
06/29 06:25:46 AM   att_loss = 3.759874889769061
06/29 06:25:46 AM   cls_loss = 0.0
06/29 06:25:46 AM   global_step = 4999
06/29 06:25:46 AM   loss = 4.87492237588982
06/29 06:25:46 AM   rep_loss = 1.1150474866573084
06/29 06:25:46 AM ***** Save model *****
06/29 06:26:15 AM ***** Running evaluation *****
06/29 06:26:15 AM   Epoch = 0 iter 5199 step
06/29 06:26:15 AM   Num examples = 9815
06/29 06:26:15 AM   Batch size = 32
06/29 06:26:15 AM ***** Eval results *****
06/29 06:26:15 AM   att_loss = 3.743897631893389
06/29 06:26:15 AM   cls_loss = 0.0
06/29 06:26:15 AM   global_step = 5199
06/29 06:26:15 AM   loss = 4.8555306342272235
06/29 06:26:15 AM   rep_loss = 1.1116330030561066
06/29 06:26:15 AM ***** Save model *****
06/29 06:26:41 AM ***** Running evaluation *****
06/29 06:26:41 AM   Epoch = 0 iter 5399 step
06/29 06:26:41 AM   Num examples = 9815
06/29 06:26:41 AM   Batch size = 32
06/29 06:26:41 AM ***** Eval results *****
06/29 06:26:41 AM   att_loss = 3.727629769795646
06/29 06:26:41 AM   cls_loss = 0.0
06/29 06:26:41 AM   global_step = 5399
06/29 06:26:41 AM   loss = 4.83582713034754
06/29 06:26:41 AM   rep_loss = 1.1081973611259708
06/29 06:26:41 AM ***** Save model *****
06/29 06:27:07 AM ***** Running evaluation *****
06/29 06:27:07 AM   Epoch = 0 iter 5599 step
06/29 06:27:07 AM   Num examples = 9815
06/29 06:27:07 AM   Batch size = 32
06/29 06:27:07 AM ***** Eval results *****
06/29 06:27:07 AM   att_loss = 3.7108949698982845
06/29 06:27:07 AM   cls_loss = 0.0
06/29 06:27:07 AM   global_step = 5599
06/29 06:27:07 AM   loss = 4.815791263731915
06/29 06:27:07 AM   rep_loss = 1.1048962944297838
06/29 06:27:07 AM ***** Save model *****
06/29 06:27:36 AM ***** Running evaluation *****
06/29 06:27:36 AM   Epoch = 0 iter 5799 step
06/29 06:27:36 AM   Num examples = 9815
06/29 06:27:36 AM   Batch size = 32
06/29 06:27:36 AM ***** Eval results *****
06/29 06:27:36 AM   att_loss = 3.695621578379692
06/29 06:27:36 AM   cls_loss = 0.0
06/29 06:27:36 AM   global_step = 5799
06/29 06:27:36 AM   loss = 4.797358015566617
06/29 06:27:36 AM   rep_loss = 1.1017364375261134
06/29 06:27:36 AM ***** Save model *****
06/29 06:28:02 AM ***** Running evaluation *****
06/29 06:28:02 AM   Epoch = 0 iter 5999 step
06/29 06:28:02 AM   Num examples = 9815
06/29 06:28:02 AM   Batch size = 32
06/29 06:28:02 AM ***** Eval results *****
06/29 06:28:02 AM   att_loss = 3.680539212637811
06/29 06:28:02 AM   cls_loss = 0.0
06/29 06:28:02 AM   global_step = 5999
06/29 06:28:02 AM   loss = 4.779219241197119
06/29 06:28:02 AM   rep_loss = 1.0986800286487295
06/29 06:28:02 AM ***** Save model *****
06/29 06:28:30 AM ***** Running evaluation *****
06/29 06:28:30 AM   Epoch = 0 iter 6199 step
06/29 06:28:30 AM   Num examples = 9815
06/29 06:28:30 AM   Batch size = 32
06/29 06:28:30 AM ***** Eval results *****
06/29 06:28:30 AM   att_loss = 3.6665403941770314
06/29 06:28:30 AM   cls_loss = 0.0
06/29 06:28:30 AM   global_step = 6199
06/29 06:28:30 AM   loss = 4.762284452750964
06/29 06:28:30 AM   rep_loss = 1.0957440585354716
06/29 06:28:30 AM ***** Save model *****
06/29 06:28:58 AM ***** Running evaluation *****
06/29 06:28:58 AM   Epoch = 0 iter 6399 step
06/29 06:28:58 AM   Num examples = 9815
06/29 06:28:58 AM   Batch size = 32
06/29 06:28:58 AM ***** Eval results *****
06/29 06:28:58 AM   att_loss = 3.6518877107736785
06/29 06:28:58 AM   cls_loss = 0.0
06/29 06:28:58 AM   global_step = 6399
06/29 06:28:58 AM   loss = 4.744735899186168
06/29 06:28:58 AM   rep_loss = 1.092848188216881
06/29 06:28:58 AM ***** Save model *****
06/29 06:29:25 AM ***** Running evaluation *****
06/29 06:29:25 AM   Epoch = 0 iter 6599 step
06/29 06:29:25 AM   Num examples = 9815
06/29 06:29:25 AM   Batch size = 32
06/29 06:29:25 AM ***** Eval results *****
06/29 06:29:25 AM   att_loss = 3.639189647967065
06/29 06:29:25 AM   cls_loss = 0.0
06/29 06:29:25 AM   global_step = 6599
06/29 06:29:25 AM   loss = 4.729340064017984
06/29 06:29:25 AM   rep_loss = 1.090150416132211
06/29 06:29:25 AM ***** Save model *****
06/29 06:29:54 AM ***** Running evaluation *****
06/29 06:29:54 AM   Epoch = 0 iter 6799 step
06/29 06:29:54 AM   Num examples = 9815
06/29 06:29:54 AM   Batch size = 32
06/29 06:29:54 AM ***** Eval results *****
06/29 06:29:54 AM   att_loss = 3.6265890126299167
06/29 06:29:54 AM   cls_loss = 0.0
06/29 06:29:54 AM   global_step = 6799
06/29 06:29:54 AM   loss = 4.7140677416389485
06/29 06:29:54 AM   rep_loss = 1.087478729508733
06/29 06:29:54 AM ***** Save model *****
06/29 06:30:20 AM ***** Running evaluation *****
06/29 06:30:20 AM   Epoch = 0 iter 6999 step
06/29 06:30:20 AM   Num examples = 9815
06/29 06:30:20 AM   Batch size = 32
06/29 06:30:20 AM ***** Eval results *****
06/29 06:30:20 AM   att_loss = 3.6140585894379584
06/29 06:30:20 AM   cls_loss = 0.0
06/29 06:30:20 AM   global_step = 6999
06/29 06:30:20 AM   loss = 4.698933030660024
06/29 06:30:20 AM   rep_loss = 1.0848744412220654
06/29 06:30:20 AM ***** Save model *****
06/29 06:30:46 AM ***** Running evaluation *****
06/29 06:30:46 AM   Epoch = 0 iter 7199 step
06/29 06:30:46 AM   Num examples = 9815
06/29 06:30:46 AM   Batch size = 32
06/29 06:30:46 AM ***** Eval results *****
06/29 06:30:46 AM   att_loss = 3.602513855208058
06/29 06:30:46 AM   cls_loss = 0.0
06/29 06:30:46 AM   global_step = 7199
06/29 06:30:46 AM   loss = 4.684887621233506
06/29 06:30:46 AM   rep_loss = 1.0823737662489967
06/29 06:30:46 AM ***** Save model *****
06/29 06:31:15 AM ***** Running evaluation *****
06/29 06:31:15 AM   Epoch = 0 iter 7399 step
06/29 06:31:15 AM   Num examples = 9815
06/29 06:31:15 AM   Batch size = 32
06/29 06:31:15 AM ***** Eval results *****
06/29 06:31:15 AM   att_loss = 3.59074002334372
06/29 06:31:15 AM   cls_loss = 0.0
06/29 06:31:15 AM   global_step = 7399
06/29 06:31:15 AM   loss = 4.670664473117437
06/29 06:31:15 AM   rep_loss = 1.079924450232896
06/29 06:31:15 AM ***** Save model *****
06/29 06:31:41 AM ***** Running evaluation *****
06/29 06:31:41 AM   Epoch = 0 iter 7599 step
06/29 06:31:41 AM   Num examples = 9815
06/29 06:31:41 AM   Batch size = 32
06/29 06:31:41 AM ***** Eval results *****
06/29 06:31:41 AM   att_loss = 3.580608848616204
06/29 06:31:41 AM   cls_loss = 0.0
06/29 06:31:41 AM   global_step = 7599
06/29 06:31:41 AM   loss = 4.658236006087795
06/29 06:31:41 AM   rep_loss = 1.0776271579657468
06/29 06:31:41 AM ***** Save model *****
06/29 06:32:07 AM ***** Running evaluation *****
06/29 06:32:07 AM   Epoch = 0 iter 7799 step
06/29 06:32:07 AM   Num examples = 9815
06/29 06:32:07 AM   Batch size = 32
06/29 06:32:07 AM ***** Eval results *****
06/29 06:32:07 AM   att_loss = 3.5695586278509186
06/29 06:32:07 AM   cls_loss = 0.0
06/29 06:32:07 AM   global_step = 7799
06/29 06:32:07 AM   loss = 4.644867206509411
06/29 06:32:07 AM   rep_loss = 1.0753085792393298
06/29 06:32:07 AM ***** Save model *****
06/29 06:32:33 AM ***** Running evaluation *****
06/29 06:32:33 AM   Epoch = 0 iter 7999 step
06/29 06:32:33 AM   Num examples = 9815
06/29 06:32:33 AM   Batch size = 32
06/29 06:32:33 AM ***** Eval results *****
06/29 06:32:33 AM   att_loss = 3.5587198188534708
06/29 06:32:33 AM   cls_loss = 0.0
06/29 06:32:33 AM   global_step = 7999
06/29 06:32:33 AM   loss = 4.63175402106099
06/29 06:32:33 AM   rep_loss = 1.0730342024385162
06/29 06:32:33 AM ***** Save model *****
06/29 06:33:00 AM ***** Running evaluation *****
06/29 06:33:00 AM   Epoch = 0 iter 8199 step
06/29 06:33:00 AM   Num examples = 9815
06/29 06:33:00 AM   Batch size = 32
06/29 06:33:00 AM ***** Eval results *****
06/29 06:33:00 AM   att_loss = 3.5491962102524086
06/29 06:33:00 AM   cls_loss = 0.0
06/29 06:33:00 AM   global_step = 8199
06/29 06:33:00 AM   loss = 4.620080652200881
06/29 06:33:00 AM   rep_loss = 1.0708844423483082
06/29 06:33:00 AM ***** Save model *****
06/29 06:33:28 AM ***** Running evaluation *****
06/29 06:33:28 AM   Epoch = 0 iter 8399 step
06/29 06:33:28 AM   Num examples = 9815
06/29 06:33:28 AM   Batch size = 32
06/29 06:33:28 AM ***** Eval results *****
06/29 06:33:28 AM   att_loss = 3.53970619118885
06/29 06:33:28 AM   cls_loss = 0.0
06/29 06:33:28 AM   global_step = 8399
06/29 06:33:28 AM   loss = 4.608478752910162
06/29 06:33:28 AM   rep_loss = 1.0687725622464623
06/29 06:33:28 AM ***** Save model *****
06/29 06:33:54 AM ***** Running evaluation *****
06/29 06:33:54 AM   Epoch = 0 iter 8599 step
06/29 06:33:54 AM   Num examples = 9815
06/29 06:33:54 AM   Batch size = 32
06/29 06:33:54 AM ***** Eval results *****
06/29 06:33:54 AM   att_loss = 3.5297918330792672
06/29 06:33:54 AM   cls_loss = 0.0
06/29 06:33:54 AM   global_step = 8599
06/29 06:33:54 AM   loss = 4.596468611115119
06/29 06:33:54 AM   rep_loss = 1.0666767789092308
06/29 06:33:54 AM ***** Save model *****
06/29 06:34:20 AM ***** Running evaluation *****
06/29 06:34:20 AM   Epoch = 0 iter 8799 step
06/29 06:34:20 AM   Num examples = 9815
06/29 06:34:20 AM   Batch size = 32
06/29 06:34:20 AM ***** Eval results *****
06/29 06:34:20 AM   att_loss = 3.52044815217274
06/29 06:34:20 AM   cls_loss = 0.0
06/29 06:34:20 AM   global_step = 8799
06/29 06:34:20 AM   loss = 4.585080916887794
06/29 06:34:20 AM   rep_loss = 1.0646327654127776
06/29 06:34:20 AM ***** Save model *****
06/29 06:34:49 AM ***** Running evaluation *****
06/29 06:34:49 AM   Epoch = 0 iter 8999 step
06/29 06:34:49 AM   Num examples = 9815
06/29 06:34:49 AM   Batch size = 32
06/29 06:34:49 AM ***** Eval results *****
06/29 06:34:49 AM   att_loss = 3.510994551830629
06/29 06:34:49 AM   cls_loss = 0.0
06/29 06:34:49 AM   global_step = 8999
06/29 06:34:49 AM   loss = 4.573619202993117
06/29 06:34:49 AM   rep_loss = 1.062624651672496
06/29 06:34:49 AM ***** Save model *****
06/29 06:35:15 AM ***** Running evaluation *****
06/29 06:35:15 AM   Epoch = 0 iter 9199 step
06/29 06:35:15 AM   Num examples = 9815
06/29 06:35:15 AM   Batch size = 32
06/29 06:35:15 AM ***** Eval results *****
06/29 06:35:15 AM   att_loss = 3.5011846049607662
06/29 06:35:15 AM   cls_loss = 0.0
06/29 06:35:15 AM   global_step = 9199
06/29 06:35:15 AM   loss = 4.561789832849686
06/29 06:35:15 AM   rep_loss = 1.0606052281416192
06/29 06:35:15 AM ***** Save model *****
06/29 06:35:42 AM ***** Running evaluation *****
06/29 06:35:42 AM   Epoch = 0 iter 9399 step
06/29 06:35:42 AM   Num examples = 9815
06/29 06:35:42 AM   Batch size = 32
06/29 06:35:42 AM ***** Eval results *****
06/29 06:35:42 AM   att_loss = 3.4928398010565607
06/29 06:35:42 AM   cls_loss = 0.0
06/29 06:35:42 AM   global_step = 9399
06/29 06:35:42 AM   loss = 4.551566689531148
06/29 06:35:42 AM   rep_loss = 1.0587268885887358
06/29 06:35:42 AM ***** Save model *****
06/29 06:36:08 AM ***** Running evaluation *****
06/29 06:36:08 AM   Epoch = 0 iter 9599 step
06/29 06:36:08 AM   Num examples = 9815
06/29 06:36:08 AM   Batch size = 32
06/29 06:36:08 AM ***** Eval results *****
06/29 06:36:08 AM   att_loss = 3.4842444998682236
06/29 06:36:08 AM   cls_loss = 0.0
06/29 06:36:08 AM   global_step = 9599
06/29 06:36:08 AM   loss = 4.5411193283886595
06/29 06:36:08 AM   rep_loss = 1.056874828582531
06/29 06:36:08 AM ***** Save model *****
06/29 06:36:34 AM ***** Running evaluation *****
06/29 06:36:34 AM   Epoch = 0 iter 9799 step
06/29 06:36:34 AM   Num examples = 9815
06/29 06:36:34 AM   Batch size = 32
06/29 06:36:34 AM ***** Eval results *****
06/29 06:36:34 AM   att_loss = 3.4756852972688743
06/29 06:36:34 AM   cls_loss = 0.0
06/29 06:36:34 AM   global_step = 9799
06/29 06:36:34 AM   loss = 4.5307279296864875
06/29 06:36:34 AM   rep_loss = 1.0550426327582463
06/29 06:36:34 AM ***** Save model *****
06/29 06:37:03 AM ***** Running evaluation *****
06/29 06:37:03 AM   Epoch = 0 iter 9999 step
06/29 06:37:03 AM   Num examples = 9815
06/29 06:37:03 AM   Batch size = 32
06/29 06:37:03 AM ***** Eval results *****
06/29 06:37:03 AM   att_loss = 3.467704877983106
06/29 06:37:03 AM   cls_loss = 0.0
06/29 06:37:03 AM   global_step = 9999
06/29 06:37:03 AM   loss = 4.520993122495119
06/29 06:37:03 AM   rep_loss = 1.0532882449114034
06/29 06:37:03 AM ***** Save model *****
06/29 06:37:29 AM ***** Running evaluation *****
06/29 06:37:29 AM   Epoch = 0 iter 10199 step
06/29 06:37:29 AM   Num examples = 9815
06/29 06:37:29 AM   Batch size = 32
06/29 06:37:29 AM ***** Eval results *****
06/29 06:37:29 AM   att_loss = 3.4595865651618873
06/29 06:37:29 AM   cls_loss = 0.0
06/29 06:37:29 AM   global_step = 10199
06/29 06:37:29 AM   loss = 4.511106198927341
06/29 06:37:29 AM   rep_loss = 1.0515196339641555
06/29 06:37:29 AM ***** Save model *****
06/29 06:37:55 AM ***** Running evaluation *****
06/29 06:37:55 AM   Epoch = 0 iter 10399 step
06/29 06:37:55 AM   Num examples = 9815
06/29 06:37:55 AM   Batch size = 32
06/29 06:37:55 AM ***** Eval results *****
06/29 06:37:55 AM   att_loss = 3.4513763170400966
06/29 06:37:55 AM   cls_loss = 0.0
06/29 06:37:55 AM   global_step = 10399
06/29 06:37:55 AM   loss = 4.501190075496949
06/29 06:37:55 AM   rep_loss = 1.049813758789295
06/29 06:37:55 AM ***** Save model *****
06/29 06:38:24 AM ***** Running evaluation *****
06/29 06:38:24 AM   Epoch = 0 iter 10599 step
06/29 06:38:24 AM   Num examples = 9815
06/29 06:38:24 AM   Batch size = 32
06/29 06:38:24 AM ***** Eval results *****
06/29 06:38:24 AM   att_loss = 3.4435403415623425
06/29 06:38:24 AM   cls_loss = 0.0
06/29 06:38:24 AM   global_step = 10599
06/29 06:38:24 AM   loss = 4.491691686351498
06/29 06:38:24 AM   rep_loss = 1.0481513449859816
06/29 06:38:24 AM ***** Save model *****
06/29 06:38:50 AM ***** Running evaluation *****
06/29 06:38:50 AM   Epoch = 0 iter 10799 step
06/29 06:38:50 AM   Num examples = 9815
06/29 06:38:50 AM   Batch size = 32
06/29 06:38:50 AM ***** Eval results *****
06/29 06:38:50 AM   att_loss = 3.435790101293392
06/29 06:38:50 AM   cls_loss = 0.0
06/29 06:38:50 AM   global_step = 10799
06/29 06:38:50 AM   loss = 4.482285240312695
06/29 06:38:50 AM   rep_loss = 1.046495139184887
06/29 06:38:50 AM ***** Save model *****
06/29 06:39:16 AM ***** Running evaluation *****
06/29 06:39:16 AM   Epoch = 0 iter 10999 step
06/29 06:39:16 AM   Num examples = 9815
06/29 06:39:16 AM   Batch size = 32
06/29 06:39:16 AM ***** Eval results *****
06/29 06:39:16 AM   att_loss = 3.4281443751002456
06/29 06:39:16 AM   cls_loss = 0.0
06/29 06:39:16 AM   global_step = 10999
06/29 06:39:16 AM   loss = 4.472995573829029
06/29 06:39:16 AM   rep_loss = 1.0448511987396214
06/29 06:39:16 AM ***** Save model *****
06/29 06:39:43 AM ***** Running evaluation *****
06/29 06:39:43 AM   Epoch = 0 iter 11199 step
06/29 06:39:43 AM   Num examples = 9815
06/29 06:39:43 AM   Batch size = 32
06/29 06:39:43 AM ***** Eval results *****
06/29 06:39:43 AM   att_loss = 3.4206381253083165
06/29 06:39:43 AM   cls_loss = 0.0
06/29 06:39:43 AM   global_step = 11199
06/29 06:39:43 AM   loss = 4.463896305904462
06/29 06:39:43 AM   rep_loss = 1.0432581807451702
06/29 06:39:43 AM ***** Save model *****
06/29 06:40:09 AM ***** Running evaluation *****
06/29 06:40:09 AM   Epoch = 0 iter 11399 step
06/29 06:40:09 AM   Num examples = 9815
06/29 06:40:09 AM   Batch size = 32
06/29 06:40:09 AM ***** Eval results *****
06/29 06:40:09 AM   att_loss = 3.413589197539982
06/29 06:40:09 AM   cls_loss = 0.0
06/29 06:40:09 AM   global_step = 11399
06/29 06:40:09 AM   loss = 4.455276987198958
06/29 06:40:09 AM   rep_loss = 1.0416877898210726
06/29 06:40:09 AM ***** Save model *****
06/29 06:40:38 AM ***** Running evaluation *****
06/29 06:40:38 AM   Epoch = 0 iter 11599 step
06/29 06:40:38 AM   Num examples = 9815
06/29 06:40:38 AM   Batch size = 32
06/29 06:40:38 AM ***** Eval results *****
06/29 06:40:38 AM   att_loss = 3.4064603534296922
06/29 06:40:38 AM   cls_loss = 0.0
06/29 06:40:38 AM   global_step = 11599
06/29 06:40:38 AM   loss = 4.446582866255626
06/29 06:40:38 AM   rep_loss = 1.0401225128721827
06/29 06:40:38 AM ***** Save model *****
06/29 06:41:05 AM ***** Running evaluation *****
06/29 06:41:05 AM   Epoch = 0 iter 11799 step
06/29 06:41:05 AM   Num examples = 9815
06/29 06:41:05 AM   Batch size = 32
06/29 06:41:05 AM ***** Eval results *****
06/29 06:41:05 AM   att_loss = 3.3999747247531844
06/29 06:41:05 AM   cls_loss = 0.0
06/29 06:41:05 AM   global_step = 11799
06/29 06:41:05 AM   loss = 4.438633642153009
06/29 06:41:05 AM   rep_loss = 1.0386589173038427
06/29 06:41:05 AM ***** Save model *****
06/29 06:41:31 AM ***** Running evaluation *****
06/29 06:41:31 AM   Epoch = 0 iter 11999 step
06/29 06:41:31 AM   Num examples = 9815
06/29 06:41:31 AM   Batch size = 32
06/29 06:41:31 AM ***** Eval results *****
06/29 06:41:31 AM   att_loss = 3.39303329452116
06/29 06:41:31 AM   cls_loss = 0.0
06/29 06:41:31 AM   global_step = 11999
06/29 06:41:31 AM   loss = 4.430195527331453
06/29 06:41:31 AM   rep_loss = 1.0371622325569523
06/29 06:41:31 AM ***** Save model *****
06/29 06:42:00 AM ***** Running evaluation *****
06/29 06:42:00 AM   Epoch = 0 iter 12199 step
06/29 06:42:00 AM   Num examples = 9815
06/29 06:42:00 AM   Batch size = 32
06/29 06:42:00 AM ***** Eval results *****
06/29 06:42:00 AM   att_loss = 3.3872782492580957
06/29 06:42:00 AM   cls_loss = 0.0
06/29 06:42:00 AM   global_step = 12199
06/29 06:42:00 AM   loss = 4.423038327446706
06/29 06:42:00 AM   rep_loss = 1.035760077910107
06/29 06:42:00 AM ***** Save model *****
06/29 06:42:27 AM ***** Running evaluation *****
06/29 06:42:27 AM   Epoch = 1 iter 12399 step
06/29 06:42:27 AM   Num examples = 9815
06/29 06:42:27 AM   Batch size = 32
06/29 06:42:27 AM ***** Eval results *****
06/29 06:42:27 AM   att_loss = 3.0184907037764788
06/29 06:42:27 AM   cls_loss = 0.0
06/29 06:42:27 AM   global_step = 12399
06/29 06:42:27 AM   loss = 3.966889539733529
06/29 06:42:27 AM   rep_loss = 0.9483988373540342
06/29 06:42:27 AM ***** Save model *****
06/29 06:42:53 AM ***** Running evaluation *****
06/29 06:42:53 AM   Epoch = 1 iter 12599 step
06/29 06:42:53 AM   Num examples = 9815
06/29 06:42:53 AM   Batch size = 32
06/29 06:42:53 AM ***** Eval results *****
06/29 06:42:53 AM   att_loss = 3.004270126179951
06/29 06:42:53 AM   cls_loss = 0.0
06/29 06:42:53 AM   global_step = 12599
06/29 06:42:53 AM   loss = 3.9511234018860795
06/29 06:42:53 AM   rep_loss = 0.9468532688007122
06/29 06:42:53 AM ***** Save model *****
06/29 06:43:20 AM ***** Running evaluation *****
06/29 06:43:20 AM   Epoch = 1 iter 12799 step
06/29 06:43:20 AM   Num examples = 9815
06/29 06:43:20 AM   Batch size = 32
06/29 06:43:20 AM ***** Eval results *****
06/29 06:43:20 AM   att_loss = 2.9777029838525886
06/29 06:43:20 AM   cls_loss = 0.0
06/29 06:43:20 AM   global_step = 12799
06/29 06:43:20 AM   loss = 3.922308216492335
06/29 06:43:20 AM   rep_loss = 0.9446052249633905
06/29 06:43:20 AM ***** Save model *****
06/29 06:43:47 AM ***** Running evaluation *****
06/29 06:43:47 AM   Epoch = 1 iter 12999 step
06/29 06:43:47 AM   Num examples = 9815
06/29 06:43:47 AM   Batch size = 32
06/29 06:43:47 AM ***** Eval results *****
06/29 06:43:47 AM   att_loss = 2.967636456201365
06/29 06:43:47 AM   cls_loss = 0.0
06/29 06:43:47 AM   global_step = 12999
06/29 06:43:47 AM   loss = 3.910908212701043
06/29 06:43:47 AM   rep_loss = 0.9432717503590898
06/29 06:43:47 AM ***** Save model *****
06/29 06:44:15 AM ***** Running evaluation *****
06/29 06:44:15 AM   Epoch = 1 iter 13199 step
06/29 06:44:15 AM   Num examples = 9815
06/29 06:44:15 AM   Batch size = 32
06/29 06:44:15 AM ***** Eval results *****
06/29 06:44:15 AM   att_loss = 2.9725416420862594
06/29 06:44:15 AM   cls_loss = 0.0
06/29 06:44:15 AM   global_step = 13199
06/29 06:44:15 AM   loss = 3.9157559822859436
06/29 06:44:15 AM   rep_loss = 0.9432143373093729
06/29 06:44:15 AM ***** Save model *****
06/29 06:44:42 AM ***** Running evaluation *****
06/29 06:44:42 AM   Epoch = 1 iter 13399 step
06/29 06:44:42 AM   Num examples = 9815
06/29 06:44:42 AM   Batch size = 32
06/29 06:44:42 AM ***** Eval results *****
06/29 06:44:42 AM   att_loss = 2.9696103930473328
06/29 06:44:42 AM   cls_loss = 0.0
06/29 06:44:42 AM   global_step = 13399
06/29 06:44:42 AM   loss = 3.912505700233135
06/29 06:44:42 AM   rep_loss = 0.9428953053363671
06/29 06:44:42 AM ***** Save model *****
06/29 06:45:09 AM ***** Running evaluation *****
06/29 06:45:09 AM   Epoch = 1 iter 13599 step
06/29 06:45:09 AM   Num examples = 9815
06/29 06:45:09 AM   Batch size = 32
06/29 06:45:09 AM ***** Eval results *****
06/29 06:45:09 AM   att_loss = 2.9653507219739708
06/29 06:45:09 AM   cls_loss = 0.0
06/29 06:45:09 AM   global_step = 13599
06/29 06:45:09 AM   loss = 3.9076009342469367
06/29 06:45:09 AM   rep_loss = 0.942250210163464
06/29 06:45:09 AM ***** Save model *****
06/29 06:45:37 AM ***** Running evaluation *****
06/29 06:45:37 AM   Epoch = 1 iter 13799 step
06/29 06:45:37 AM   Num examples = 9815
06/29 06:45:37 AM   Batch size = 32
06/29 06:45:37 AM ***** Eval results *****
06/29 06:45:37 AM   att_loss = 2.965590556878694
06/29 06:45:37 AM   cls_loss = 0.0
06/29 06:45:37 AM   global_step = 13799
06/29 06:45:37 AM   loss = 3.90738646756292
06/29 06:45:37 AM   rep_loss = 0.9417959102161267
06/29 06:45:37 AM ***** Save model *****
06/29 06:46:03 AM ***** Running evaluation *****
06/29 06:46:03 AM   Epoch = 1 iter 13999 step
06/29 06:46:03 AM   Num examples = 9815
06/29 06:46:03 AM   Batch size = 32
06/29 06:46:03 AM ***** Eval results *****
06/29 06:46:03 AM   att_loss = 2.9571712900091103
06/29 06:46:03 AM   cls_loss = 0.0
06/29 06:46:03 AM   global_step = 13999
06/29 06:46:03 AM   loss = 3.8979048310882516
06/29 06:46:03 AM   rep_loss = 0.9407335405617401
06/29 06:46:03 AM ***** Save model *****
06/29 06:46:30 AM ***** Running evaluation *****
06/29 06:46:30 AM   Epoch = 1 iter 14199 step
06/29 06:46:30 AM   Num examples = 9815
06/29 06:46:30 AM   Batch size = 32
06/29 06:46:30 AM ***** Eval results *****
06/29 06:46:30 AM   att_loss = 2.9531468230906364
06/29 06:46:30 AM   cls_loss = 0.0
06/29 06:46:30 AM   global_step = 14199
06/29 06:46:30 AM   loss = 3.893096229842095
06/29 06:46:30 AM   rep_loss = 0.9399494069987807
06/29 06:46:30 AM ***** Save model *****
06/29 06:46:57 AM ***** Running evaluation *****
06/29 06:46:57 AM   Epoch = 1 iter 14399 step
06/29 06:46:57 AM   Num examples = 9815
06/29 06:46:57 AM   Batch size = 32
06/29 06:46:57 AM ***** Eval results *****
06/29 06:46:57 AM   att_loss = 2.9523899321045195
06/29 06:46:57 AM   cls_loss = 0.0
06/29 06:46:57 AM   global_step = 14399
06/29 06:46:57 AM   loss = 3.8918152845891796
06/29 06:46:57 AM   rep_loss = 0.9394253536050481
06/29 06:46:57 AM ***** Save model *****
06/29 06:47:25 AM ***** Running evaluation *****
06/29 06:47:25 AM   Epoch = 1 iter 14599 step
06/29 06:47:25 AM   Num examples = 9815
06/29 06:47:25 AM   Batch size = 32
06/29 06:47:25 AM ***** Eval results *****
06/29 06:47:25 AM   att_loss = 2.9514254722808233
06/29 06:47:25 AM   cls_loss = 0.0
06/29 06:47:25 AM   global_step = 14599
06/29 06:47:25 AM   loss = 3.8902854355135323
06/29 06:47:25 AM   rep_loss = 0.9388599650761515
06/29 06:47:25 AM ***** Save model *****
06/29 06:47:54 AM ***** Running evaluation *****
06/29 06:47:54 AM   Epoch = 1 iter 14799 step
06/29 06:47:54 AM   Num examples = 9815
06/29 06:47:54 AM   Batch size = 32
06/29 06:47:54 AM ***** Eval results *****
06/29 06:47:54 AM   att_loss = 2.950290799706797
06/29 06:47:54 AM   cls_loss = 0.0
06/29 06:47:54 AM   global_step = 14799
06/29 06:47:54 AM   loss = 3.88858176513186
06/29 06:47:54 AM   rep_loss = 0.9382909667925744
06/29 06:47:54 AM ***** Save model *****
06/29 06:48:20 AM ***** Running evaluation *****
06/29 06:48:20 AM   Epoch = 1 iter 14999 step
06/29 06:48:20 AM   Num examples = 9815
06/29 06:48:20 AM   Batch size = 32
06/29 06:48:20 AM ***** Eval results *****
06/29 06:48:20 AM   att_loss = 2.9456291337691445
06/29 06:48:20 AM   cls_loss = 0.0
06/29 06:48:20 AM   global_step = 14999
06/29 06:48:20 AM   loss = 3.883156588088033
06/29 06:48:20 AM   rep_loss = 0.9375274546029281
06/29 06:48:20 AM ***** Save model *****
06/29 06:48:46 AM ***** Running evaluation *****
06/29 06:48:46 AM   Epoch = 1 iter 15199 step
06/29 06:48:46 AM   Num examples = 9815
06/29 06:48:46 AM   Batch size = 32
06/29 06:48:46 AM ***** Eval results *****
06/29 06:48:46 AM   att_loss = 2.9424912489014243
06/29 06:48:46 AM   cls_loss = 0.0
06/29 06:48:46 AM   global_step = 15199
06/29 06:48:46 AM   loss = 3.879326705724164
06/29 06:48:46 AM   rep_loss = 0.9368354571280909
06/29 06:48:46 AM ***** Save model *****
06/29 06:49:14 AM ***** Running evaluation *****
06/29 06:49:14 AM   Epoch = 1 iter 15399 step
06/29 06:49:14 AM   Num examples = 9815
06/29 06:49:14 AM   Batch size = 32
06/29 06:49:14 AM ***** Eval results *****
06/29 06:49:14 AM   att_loss = 2.9382536687966807
06/29 06:49:14 AM   cls_loss = 0.0
06/29 06:49:14 AM   global_step = 15399
06/29 06:49:14 AM   loss = 3.8743528115474963
06/29 06:49:14 AM   rep_loss = 0.936099142884202
06/29 06:49:14 AM ***** Save model *****
06/29 06:49:41 AM ***** Running evaluation *****
06/29 06:49:41 AM   Epoch = 1 iter 15599 step
06/29 06:49:41 AM   Num examples = 9815
06/29 06:49:41 AM   Batch size = 32
06/29 06:49:41 AM ***** Eval results *****
06/29 06:49:41 AM   att_loss = 2.9357543982422123
06/29 06:49:41 AM   cls_loss = 0.0
06/29 06:49:41 AM   global_step = 15599
06/29 06:49:41 AM   loss = 3.871280658775224
06/29 06:49:41 AM   rep_loss = 0.9355262610524033
06/29 06:49:41 AM ***** Save model *****
06/29 06:50:08 AM ***** Running evaluation *****
06/29 06:50:08 AM   Epoch = 1 iter 15799 step
06/29 06:50:08 AM   Num examples = 9815
06/29 06:50:08 AM   Batch size = 32
06/29 06:50:08 AM ***** Eval results *****
06/29 06:50:08 AM   att_loss = 2.9341301653796044
06/29 06:50:08 AM   cls_loss = 0.0
06/29 06:50:08 AM   global_step = 15799
06/29 06:50:08 AM   loss = 3.869128867274239
06/29 06:50:08 AM   rep_loss = 0.9349987022494243
06/29 06:50:08 AM ***** Save model *****
06/29 06:50:35 AM ***** Running evaluation *****
06/29 06:50:35 AM   Epoch = 1 iter 15999 step
06/29 06:50:35 AM   Num examples = 9815
06/29 06:50:35 AM   Batch size = 32
06/29 06:50:35 AM ***** Eval results *****
06/29 06:50:35 AM   att_loss = 2.9312883266307765
06/29 06:50:35 AM   cls_loss = 0.0
06/29 06:50:35 AM   global_step = 15999
06/29 06:50:35 AM   loss = 3.865701253449968
06/29 06:50:35 AM   rep_loss = 0.9344129272668659
06/29 06:50:35 AM ***** Save model *****
06/29 06:51:01 AM ***** Running evaluation *****
06/29 06:51:01 AM   Epoch = 1 iter 16199 step
06/29 06:51:01 AM   Num examples = 9815
06/29 06:51:01 AM   Batch size = 32
06/29 06:51:01 AM ***** Eval results *****
06/29 06:51:01 AM   att_loss = 2.9279740974762287
06/29 06:51:01 AM   cls_loss = 0.0
06/29 06:51:01 AM   global_step = 16199
06/29 06:51:01 AM   loss = 3.8617483352570816
06/29 06:51:01 AM   rep_loss = 0.93377423805399
06/29 06:51:01 AM ***** Save model *****
06/29 06:51:30 AM ***** Running evaluation *****
06/29 06:51:30 AM   Epoch = 1 iter 16399 step
06/29 06:51:30 AM   Num examples = 9815
06/29 06:51:30 AM   Batch size = 32
06/29 06:51:30 AM ***** Eval results *****
06/29 06:51:30 AM   att_loss = 2.925699932226377
06/29 06:51:30 AM   cls_loss = 0.0
06/29 06:51:30 AM   global_step = 16399
06/29 06:51:30 AM   loss = 3.858922146087469
06/29 06:51:30 AM   rep_loss = 0.9332222141787525
06/29 06:51:30 AM ***** Save model *****
06/29 06:51:56 AM ***** Running evaluation *****
06/29 06:51:56 AM   Epoch = 1 iter 16599 step
06/29 06:51:56 AM   Num examples = 9815
06/29 06:51:56 AM   Batch size = 32
06/29 06:51:56 AM ***** Eval results *****
06/29 06:51:56 AM   att_loss = 2.9258255144915166
06/29 06:51:56 AM   cls_loss = 0.0
06/29 06:51:56 AM   global_step = 16599
06/29 06:51:56 AM   loss = 3.8585973681672003
06/29 06:51:56 AM   rep_loss = 0.9327718545295395
06/29 06:51:56 AM ***** Save model *****
06/29 06:52:23 AM ***** Running evaluation *****
06/29 06:52:23 AM   Epoch = 1 iter 16799 step
06/29 06:52:23 AM   Num examples = 9815
06/29 06:52:23 AM   Batch size = 32
06/29 06:52:23 AM ***** Eval results *****
06/29 06:52:23 AM   att_loss = 2.9244184615123396
06/29 06:52:23 AM   cls_loss = 0.0
06/29 06:52:23 AM   global_step = 16799
06/29 06:52:23 AM   loss = 3.856712541710783
06/29 06:52:23 AM   rep_loss = 0.9322940810145843
06/29 06:52:23 AM ***** Save model *****
06/29 06:52:51 AM ***** Running evaluation *****
06/29 06:52:51 AM   Epoch = 1 iter 16999 step
06/29 06:52:51 AM   Num examples = 9815
06/29 06:52:51 AM   Batch size = 32
06/29 06:52:51 AM ***** Eval results *****
06/29 06:52:51 AM   att_loss = 2.923479661824538
06/29 06:52:51 AM   cls_loss = 0.0
06/29 06:52:51 AM   global_step = 16999
06/29 06:52:51 AM   loss = 3.8552199662639404
06/29 06:52:51 AM   rep_loss = 0.9317403050697395
06/29 06:52:51 AM ***** Save model *****
06/29 06:53:17 AM ***** Running evaluation *****
06/29 06:53:17 AM   Epoch = 1 iter 17199 step
06/29 06:53:17 AM   Num examples = 9815
06/29 06:53:17 AM   Batch size = 32
06/29 06:53:17 AM ***** Eval results *****
06/29 06:53:17 AM   att_loss = 2.921691787030016
06/29 06:53:17 AM   cls_loss = 0.0
06/29 06:53:17 AM   global_step = 17199
06/29 06:53:17 AM   loss = 3.852892223068259
06/29 06:53:17 AM   rep_loss = 0.9312004370421365
06/29 06:53:17 AM ***** Save model *****
06/29 06:53:43 AM ***** Running evaluation *****
06/29 06:53:43 AM   Epoch = 1 iter 17399 step
06/29 06:53:43 AM   Num examples = 9815
06/29 06:53:43 AM   Batch size = 32
06/29 06:53:43 AM ***** Eval results *****
06/29 06:53:43 AM   att_loss = 2.920018875003791
06/29 06:53:43 AM   cls_loss = 0.0
06/29 06:53:43 AM   global_step = 17399
06/29 06:53:43 AM   loss = 3.8507155963857533
06/29 06:53:43 AM   rep_loss = 0.9306967223350789
06/29 06:53:43 AM ***** Save model *****
06/29 06:54:09 AM ***** Running evaluation *****
06/29 06:54:09 AM   Epoch = 1 iter 17599 step
06/29 06:54:09 AM   Num examples = 9815
06/29 06:54:09 AM   Batch size = 32
06/29 06:54:09 AM ***** Eval results *****
06/29 06:54:09 AM   att_loss = 2.9177518462365097
06/29 06:54:09 AM   cls_loss = 0.0
06/29 06:54:09 AM   global_step = 17599
06/29 06:54:09 AM   loss = 3.8479453402238564
06/29 06:54:09 AM   rep_loss = 0.9301934949046856
06/29 06:54:09 AM ***** Save model *****
06/29 06:54:36 AM ***** Running evaluation *****
06/29 06:54:36 AM   Epoch = 1 iter 17799 step
06/29 06:54:36 AM   Num examples = 9815
06/29 06:54:36 AM   Batch size = 32
06/29 06:54:36 AM ***** Eval results *****
06/29 06:54:36 AM   att_loss = 2.9161911746527456
06/29 06:54:36 AM   cls_loss = 0.0
06/29 06:54:36 AM   global_step = 17799
06/29 06:54:36 AM   loss = 3.8459086526837605
06/29 06:54:36 AM   rep_loss = 0.929717479432716
06/29 06:54:36 AM ***** Save model *****
06/29 06:55:04 AM ***** Running evaluation *****
06/29 06:55:04 AM   Epoch = 1 iter 17999 step
06/29 06:55:04 AM   Num examples = 9815
06/29 06:55:04 AM   Batch size = 32
06/29 06:55:04 AM ***** Eval results *****
06/29 06:55:04 AM   att_loss = 2.9134583111082377
06/29 06:55:04 AM   cls_loss = 0.0
06/29 06:55:04 AM   global_step = 17999
06/29 06:55:04 AM   loss = 3.8425760597573313
06/29 06:55:04 AM   rep_loss = 0.9291177500955052
06/29 06:55:04 AM ***** Save model *****
06/29 06:55:30 AM ***** Running evaluation *****
06/29 06:55:30 AM   Epoch = 1 iter 18199 step
06/29 06:55:30 AM   Num examples = 9815
06/29 06:55:30 AM   Batch size = 32
06/29 06:55:30 AM ***** Eval results *****
06/29 06:55:30 AM   att_loss = 2.9121286065874474
06/29 06:55:30 AM   cls_loss = 0.0
06/29 06:55:30 AM   global_step = 18199
06/29 06:55:30 AM   loss = 3.840791899303676
06/29 06:55:30 AM   rep_loss = 0.9286632937217049
06/29 06:55:30 AM ***** Save model *****
06/29 06:55:57 AM ***** Running evaluation *****
06/29 06:55:57 AM   Epoch = 1 iter 18399 step
06/29 06:55:57 AM   Num examples = 9815
06/29 06:55:57 AM   Batch size = 32
06/29 06:55:57 AM ***** Eval results *****
06/29 06:55:57 AM   att_loss = 2.9098722884922674
06/29 06:55:57 AM   cls_loss = 0.0
06/29 06:55:57 AM   global_step = 18399
06/29 06:55:57 AM   loss = 3.838026372555342
06/29 06:55:57 AM   rep_loss = 0.9281540848314762
06/29 06:55:57 AM ***** Save model *****
06/29 06:56:25 AM ***** Running evaluation *****
06/29 06:56:25 AM   Epoch = 1 iter 18599 step
06/29 06:56:25 AM   Num examples = 9815
06/29 06:56:25 AM   Batch size = 32
06/29 06:56:25 AM ***** Eval results *****
06/29 06:56:25 AM   att_loss = 2.9084812818676724
06/29 06:56:25 AM   cls_loss = 0.0
06/29 06:56:25 AM   global_step = 18599
06/29 06:56:25 AM   loss = 3.836179120350728
06/29 06:56:25 AM   rep_loss = 0.9276978392271719
06/29 06:56:25 AM ***** Save model *****
06/29 06:56:51 AM ***** Running evaluation *****
06/29 06:56:51 AM   Epoch = 1 iter 18799 step
06/29 06:56:51 AM   Num examples = 9815
06/29 06:56:51 AM   Batch size = 32
06/29 06:56:51 AM ***** Eval results *****
06/29 06:56:51 AM   att_loss = 2.9062305419687546
06/29 06:56:51 AM   cls_loss = 0.0
06/29 06:56:51 AM   global_step = 18799
06/29 06:56:51 AM   loss = 3.833392247009803
06/29 06:56:51 AM   rep_loss = 0.9271617058536732
06/29 06:56:51 AM ***** Save model *****
06/29 06:57:17 AM ***** Running evaluation *****
06/29 06:57:17 AM   Epoch = 1 iter 18999 step
06/29 06:57:17 AM   Num examples = 9815
06/29 06:57:17 AM   Batch size = 32
06/29 06:57:17 AM ***** Eval results *****
06/29 06:57:17 AM   att_loss = 2.9055194079025464
06/29 06:57:17 AM   cls_loss = 0.0
06/29 06:57:17 AM   global_step = 18999
06/29 06:57:17 AM   loss = 3.832274277343478
06/29 06:57:17 AM   rep_loss = 0.9267548701585261
06/29 06:57:17 AM ***** Save model *****
06/29 06:57:44 AM ***** Running evaluation *****
06/29 06:57:44 AM   Epoch = 1 iter 19199 step
06/29 06:57:44 AM   Num examples = 9815
06/29 06:57:44 AM   Batch size = 32
06/29 06:57:44 AM ***** Eval results *****
06/29 06:57:44 AM   att_loss = 2.902321587465101
06/29 06:57:44 AM   cls_loss = 0.0
06/29 06:57:44 AM   global_step = 19199
06/29 06:57:44 AM   loss = 3.828481469157111
06/29 06:57:44 AM   rep_loss = 0.9261598823458713
06/29 06:57:44 AM ***** Save model *****
06/29 06:58:11 AM ***** Running evaluation *****
06/29 06:58:11 AM   Epoch = 1 iter 19399 step
06/29 06:58:11 AM   Num examples = 9815
06/29 06:58:11 AM   Batch size = 32
06/29 06:58:11 AM ***** Eval results *****
06/29 06:58:11 AM   att_loss = 2.9016793940538244
06/29 06:58:11 AM   cls_loss = 0.0
06/29 06:58:11 AM   global_step = 19399
06/29 06:58:11 AM   loss = 3.8274281529331313
06/29 06:58:11 AM   rep_loss = 0.9257487596987876
06/29 06:58:11 AM ***** Save model *****
06/29 06:58:40 AM ***** Running evaluation *****
06/29 06:58:40 AM   Epoch = 1 iter 19599 step
06/29 06:58:40 AM   Num examples = 9815
06/29 06:58:40 AM   Batch size = 32
06/29 06:58:40 AM ***** Eval results *****
06/29 06:58:40 AM   att_loss = 2.89886748907868
06/29 06:58:40 AM   cls_loss = 0.0
06/29 06:58:40 AM   global_step = 19599
06/29 06:58:40 AM   loss = 3.824065080961806
06/29 06:58:40 AM   rep_loss = 0.9251975927697128
06/29 06:58:40 AM ***** Save model *****
06/29 06:59:06 AM ***** Running evaluation *****
06/29 06:59:06 AM   Epoch = 1 iter 19799 step
06/29 06:59:06 AM   Num examples = 9815
06/29 06:59:06 AM   Batch size = 32
06/29 06:59:06 AM ***** Eval results *****
06/29 06:59:06 AM   att_loss = 2.8971983090470625
06/29 06:59:06 AM   cls_loss = 0.0
06/29 06:59:06 AM   global_step = 19799
06/29 06:59:06 AM   loss = 3.8219336283637664
06/29 06:59:06 AM   rep_loss = 0.9247353202589134
06/29 06:59:06 AM ***** Save model *****
06/29 06:59:33 AM ***** Running evaluation *****
06/29 06:59:33 AM   Epoch = 1 iter 19999 step
06/29 06:59:33 AM   Num examples = 9815
06/29 06:59:33 AM   Batch size = 32
06/29 06:59:33 AM ***** Eval results *****
06/29 06:59:33 AM   att_loss = 2.8963416306683736
06/29 06:59:33 AM   cls_loss = 0.0
06/29 06:59:33 AM   global_step = 19999
06/29 06:59:33 AM   loss = 3.820668040410332
06/29 06:59:33 AM   rep_loss = 0.9243264108063272
06/29 06:59:33 AM ***** Save model *****
06/29 07:00:01 AM ***** Running evaluation *****
06/29 07:00:01 AM   Epoch = 1 iter 20199 step
06/29 07:00:01 AM   Num examples = 9815
06/29 07:00:01 AM   Batch size = 32
06/29 07:00:01 AM ***** Eval results *****
06/29 07:00:01 AM   att_loss = 2.8947125568189005
06/29 07:00:01 AM   cls_loss = 0.0
06/29 07:00:01 AM   global_step = 20199
06/29 07:00:01 AM   loss = 3.818540470541185
06/29 07:00:01 AM   rep_loss = 0.9238279148800943
06/29 07:00:01 AM ***** Save model *****
06/29 07:00:28 AM ***** Running evaluation *****
06/29 07:00:28 AM   Epoch = 1 iter 20399 step
06/29 07:00:28 AM   Num examples = 9815
06/29 07:00:28 AM   Batch size = 32
06/29 07:00:28 AM ***** Eval results *****
06/29 07:00:28 AM   att_loss = 2.893715891649756
06/29 07:00:28 AM   cls_loss = 0.0
06/29 07:00:28 AM   global_step = 20399
06/29 07:00:28 AM   loss = 3.8171121281549687
06/29 07:00:28 AM   rep_loss = 0.9233962377371985
06/29 07:00:28 AM ***** Save model *****
06/29 07:00:54 AM ***** Running evaluation *****
06/29 07:00:54 AM   Epoch = 1 iter 20599 step
06/29 07:00:54 AM   Num examples = 9815
06/29 07:00:54 AM   Batch size = 32
06/29 07:00:54 AM ***** Eval results *****
06/29 07:00:54 AM   att_loss = 2.892152510948415
06/29 07:00:54 AM   cls_loss = 0.0
06/29 07:00:54 AM   global_step = 20599
06/29 07:00:54 AM   loss = 3.815114701229374
06/29 07:00:54 AM   rep_loss = 0.9229621914261013
06/29 07:00:54 AM ***** Save model *****
06/29 07:01:20 AM ***** Running evaluation *****
06/29 07:01:20 AM   Epoch = 1 iter 20799 step
06/29 07:01:20 AM   Num examples = 9815
06/29 07:01:20 AM   Batch size = 32
06/29 07:01:20 AM ***** Eval results *****
06/29 07:01:20 AM   att_loss = 2.890275096202769
06/29 07:01:20 AM   cls_loss = 0.0
06/29 07:01:20 AM   global_step = 20799
06/29 07:01:20 AM   loss = 3.812803970380751
06/29 07:01:20 AM   rep_loss = 0.9225288752683108
06/29 07:01:20 AM ***** Save model *****
06/29 07:01:46 AM ***** Running evaluation *****
06/29 07:01:46 AM   Epoch = 1 iter 20999 step
06/29 07:01:46 AM   Num examples = 9815
06/29 07:01:46 AM   Batch size = 32
06/29 07:01:46 AM ***** Eval results *****
06/29 07:01:46 AM   att_loss = 2.8884685256003677
06/29 07:01:46 AM   cls_loss = 0.0
06/29 07:01:46 AM   global_step = 20999
06/29 07:01:46 AM   loss = 3.810531411910691
06/29 07:01:46 AM   rep_loss = 0.9220628872459138
06/29 07:01:46 AM ***** Save model *****
06/29 07:02:14 AM ***** Running evaluation *****
06/29 07:02:14 AM   Epoch = 1 iter 21199 step
06/29 07:02:14 AM   Num examples = 9815
06/29 07:02:14 AM   Batch size = 32
06/29 07:02:14 AM ***** Eval results *****
06/29 07:02:14 AM   att_loss = 2.8864778400028266
06/29 07:02:14 AM   cls_loss = 0.0
06/29 07:02:14 AM   global_step = 21199
06/29 07:02:14 AM   loss = 3.8080903936084027
06/29 07:02:14 AM   rep_loss = 0.9216125546203505
06/29 07:02:14 AM ***** Save model *****
06/29 07:02:40 AM ***** Running evaluation *****
06/29 07:02:40 AM   Epoch = 1 iter 21399 step
06/29 07:02:40 AM   Num examples = 9815
06/29 07:02:40 AM   Batch size = 32
06/29 07:02:40 AM ***** Eval results *****
06/29 07:02:40 AM   att_loss = 2.884315941296681
06/29 07:02:40 AM   cls_loss = 0.0
06/29 07:02:40 AM   global_step = 21399
06/29 07:02:40 AM   loss = 3.805479014943714
06/29 07:02:40 AM   rep_loss = 0.9211630748942377
06/29 07:02:40 AM ***** Save model *****
06/29 07:03:06 AM ***** Running evaluation *****
06/29 07:03:06 AM   Epoch = 1 iter 21599 step
06/29 07:03:06 AM   Num examples = 9815
06/29 07:03:06 AM   Batch size = 32
06/29 07:03:06 AM ***** Eval results *****
06/29 07:03:06 AM   att_loss = 2.8830704594328105
06/29 07:03:06 AM   cls_loss = 0.0
06/29 07:03:06 AM   global_step = 21599
06/29 07:03:06 AM   loss = 3.8038473202883685
06/29 07:03:06 AM   rep_loss = 0.920776862076022
06/29 07:03:06 AM ***** Save model *****
06/29 07:03:35 AM ***** Running evaluation *****
06/29 07:03:35 AM   Epoch = 1 iter 21799 step
06/29 07:03:35 AM   Num examples = 9815
06/29 07:03:35 AM   Batch size = 32
06/29 07:03:35 AM ***** Eval results *****
06/29 07:03:35 AM   att_loss = 2.881396069522168
06/29 07:03:35 AM   cls_loss = 0.0
06/29 07:03:35 AM   global_step = 21799
06/29 07:03:35 AM   loss = 3.8017402040568045
06/29 07:03:35 AM   rep_loss = 0.9203441357419934
06/29 07:03:35 AM ***** Save model *****
06/29 07:04:01 AM ***** Running evaluation *****
06/29 07:04:01 AM   Epoch = 1 iter 21999 step
06/29 07:04:01 AM   Num examples = 9815
06/29 07:04:01 AM   Batch size = 32
06/29 07:04:01 AM ***** Eval results *****
06/29 07:04:01 AM   att_loss = 2.8795825349485598
06/29 07:04:01 AM   cls_loss = 0.0
06/29 07:04:01 AM   global_step = 21999
06/29 07:04:01 AM   loss = 3.799464703194405
06/29 07:04:01 AM   rep_loss = 0.9198821693609812
06/29 07:04:01 AM ***** Save model *****
06/29 07:04:27 AM ***** Running evaluation *****
06/29 07:04:27 AM   Epoch = 1 iter 22199 step
06/29 07:04:27 AM   Num examples = 9815
06/29 07:04:27 AM   Batch size = 32
06/29 07:04:27 AM ***** Eval results *****
06/29 07:04:27 AM   att_loss = 2.8783455840360723
06/29 07:04:27 AM   cls_loss = 0.0
06/29 07:04:27 AM   global_step = 22199
06/29 07:04:27 AM   loss = 3.797835738187255
06/29 07:04:27 AM   rep_loss = 0.9194901553158987
06/29 07:04:27 AM ***** Save model *****
06/29 07:04:53 AM ***** Running evaluation *****
06/29 07:04:53 AM   Epoch = 1 iter 22399 step
06/29 07:04:53 AM   Num examples = 9815
06/29 07:04:53 AM   Batch size = 32
06/29 07:04:53 AM ***** Eval results *****
06/29 07:04:53 AM   att_loss = 2.8771381713979616
06/29 07:04:53 AM   cls_loss = 0.0
06/29 07:04:53 AM   global_step = 22399
06/29 07:04:53 AM   loss = 3.796229462323219
06/29 07:04:53 AM   rep_loss = 0.9190912921729057
06/29 07:04:53 AM ***** Save model *****
06/29 07:05:19 AM ***** Running evaluation *****
06/29 07:05:19 AM   Epoch = 1 iter 22599 step
06/29 07:05:19 AM   Num examples = 9815
06/29 07:05:19 AM   Batch size = 32
06/29 07:05:19 AM ***** Eval results *****
06/29 07:05:19 AM   att_loss = 2.8754862491171274
06/29 07:05:19 AM   cls_loss = 0.0
06/29 07:05:19 AM   global_step = 22599
06/29 07:05:19 AM   loss = 3.7941590686300573
06/29 07:05:19 AM   rep_loss = 0.9186728207883588
06/29 07:05:19 AM ***** Save model *****
06/29 07:05:48 AM ***** Running evaluation *****
06/29 07:05:48 AM   Epoch = 1 iter 22799 step
06/29 07:05:48 AM   Num examples = 9815
06/29 07:05:48 AM   Batch size = 32
06/29 07:05:48 AM ***** Eval results *****
06/29 07:05:48 AM   att_loss = 2.8739140422895866
06/29 07:05:48 AM   cls_loss = 0.0
06/29 07:05:48 AM   global_step = 22799
06/29 07:05:48 AM   loss = 3.792153480658053
06/29 07:05:48 AM   rep_loss = 0.91823943971025
06/29 07:05:48 AM ***** Save model *****
06/29 07:06:14 AM ***** Running evaluation *****
06/29 07:06:14 AM   Epoch = 1 iter 22999 step
06/29 07:06:14 AM   Num examples = 9815
06/29 07:06:14 AM   Batch size = 32
06/29 07:06:14 AM ***** Eval results *****
06/29 07:06:14 AM   att_loss = 2.8725607871764813
06/29 07:06:14 AM   cls_loss = 0.0
06/29 07:06:14 AM   global_step = 22999
06/29 07:06:14 AM   loss = 3.790404531313002
06/29 07:06:14 AM   rep_loss = 0.917843745553298
06/29 07:06:14 AM ***** Save model *****
06/29 07:06:41 AM ***** Running evaluation *****
06/29 07:06:41 AM   Epoch = 1 iter 23199 step
06/29 07:06:41 AM   Num examples = 9815
06/29 07:06:41 AM   Batch size = 32
06/29 07:06:41 AM ***** Eval results *****
06/29 07:06:41 AM   att_loss = 2.8706493046500148
06/29 07:06:41 AM   cls_loss = 0.0
06/29 07:06:41 AM   global_step = 23199
06/29 07:06:41 AM   loss = 3.7880692163245047
06/29 07:06:41 AM   rep_loss = 0.917419912770805
06/29 07:06:41 AM ***** Save model *****
06/29 07:07:09 AM ***** Running evaluation *****
06/29 07:07:09 AM   Epoch = 1 iter 23399 step
06/29 07:07:09 AM   Num examples = 9815
06/29 07:07:09 AM   Batch size = 32
06/29 07:07:09 AM ***** Eval results *****
06/29 07:07:09 AM   att_loss = 2.86885966511616
06/29 07:07:09 AM   cls_loss = 0.0
06/29 07:07:09 AM   global_step = 23399
06/29 07:07:09 AM   loss = 3.785871279980963
06/29 07:07:09 AM   rep_loss = 0.9170116158503581
06/29 07:07:09 AM ***** Save model *****
06/29 07:07:36 AM ***** Running evaluation *****
06/29 07:07:36 AM   Epoch = 1 iter 23599 step
06/29 07:07:36 AM   Num examples = 9815
06/29 07:07:36 AM   Batch size = 32
06/29 07:07:36 AM ***** Eval results *****
06/29 07:07:36 AM   att_loss = 2.8680949593120713
06/29 07:07:36 AM   cls_loss = 0.0
06/29 07:07:36 AM   global_step = 23599
06/29 07:07:36 AM   loss = 3.7847361611149744
06/29 07:07:36 AM   rep_loss = 0.9166412026552999
06/29 07:07:36 AM ***** Save model *****
06/29 07:08:02 AM ***** Running evaluation *****
06/29 07:08:02 AM   Epoch = 1 iter 23799 step
06/29 07:08:02 AM   Num examples = 9815
06/29 07:08:02 AM   Batch size = 32
06/29 07:08:02 AM ***** Eval results *****
06/29 07:08:02 AM   att_loss = 2.8664058238619488
06/29 07:08:02 AM   cls_loss = 0.0
06/29 07:08:02 AM   global_step = 23799
06/29 07:08:02 AM   loss = 3.7826424537641485
06/29 07:08:02 AM   rep_loss = 0.9162366307346379
06/29 07:08:02 AM ***** Save model *****
06/29 07:08:28 AM ***** Running evaluation *****
06/29 07:08:28 AM   Epoch = 1 iter 23999 step
06/29 07:08:28 AM   Num examples = 9815
06/29 07:08:28 AM   Batch size = 32
06/29 07:08:28 AM ***** Eval results *****
06/29 07:08:28 AM   att_loss = 2.8644516220542453
06/29 07:08:28 AM   cls_loss = 0.0
06/29 07:08:28 AM   global_step = 23999
06/29 07:08:28 AM   loss = 3.78026329281792
06/29 07:08:28 AM   rep_loss = 0.9158116716530688
06/29 07:08:28 AM ***** Save model *****
06/29 07:08:55 AM ***** Running evaluation *****
06/29 07:08:55 AM   Epoch = 1 iter 24199 step
06/29 07:08:55 AM   Num examples = 9815
06/29 07:08:55 AM   Batch size = 32
06/29 07:08:55 AM ***** Eval results *****
06/29 07:08:55 AM   att_loss = 2.863426803493164
06/29 07:08:55 AM   cls_loss = 0.0
06/29 07:08:55 AM   global_step = 24199
06/29 07:08:55 AM   loss = 3.7788714021944023
06/29 07:08:55 AM   rep_loss = 0.9154445994358028
06/29 07:08:55 AM ***** Save model *****
06/29 07:09:23 AM ***** Running evaluation *****
06/29 07:09:23 AM   Epoch = 1 iter 24399 step
06/29 07:09:23 AM   Num examples = 9815
06/29 07:09:23 AM   Batch size = 32
06/29 07:09:23 AM ***** Eval results *****
06/29 07:09:23 AM   att_loss = 2.8622095409810226
06/29 07:09:23 AM   cls_loss = 0.0
06/29 07:09:23 AM   global_step = 24399
06/29 07:09:23 AM   loss = 3.777289011960451
06/29 07:09:23 AM   rep_loss = 0.9150794716134156
06/29 07:09:23 AM ***** Save model *****
06/29 07:09:49 AM ***** Running evaluation *****
06/29 07:09:49 AM   Epoch = 2 iter 24599 step
06/29 07:09:49 AM   Num examples = 9815
06/29 07:09:49 AM   Batch size = 32
06/29 07:09:49 AM ***** Eval results *****
06/29 07:09:49 AM   att_loss = 2.78436709705152
06/29 07:09:49 AM   cls_loss = 0.0
06/29 07:09:49 AM   global_step = 24599
06/29 07:09:49 AM   loss = 3.6726736687777337
06/29 07:09:49 AM   rep_loss = 0.8883065633606493
06/29 07:09:49 AM ***** Save model *****
06/29 07:10:15 AM ***** Running evaluation *****
06/29 07:10:15 AM   Epoch = 2 iter 24799 step
06/29 07:10:15 AM   Num examples = 9815
06/29 07:10:15 AM   Batch size = 32
06/29 07:10:15 AM ***** Eval results *****
06/29 07:10:15 AM   att_loss = 2.782317007562066
06/29 07:10:15 AM   cls_loss = 0.0
06/29 07:10:15 AM   global_step = 24799
06/29 07:10:15 AM   loss = 3.672911799835324
06/29 07:10:15 AM   rep_loss = 0.8905948013183208
06/29 07:10:15 AM ***** Save model *****
06/29 07:10:44 AM ***** Running evaluation *****
06/29 07:10:44 AM   Epoch = 2 iter 24999 step
06/29 07:10:44 AM   Num examples = 9815
06/29 07:10:44 AM   Batch size = 32
06/29 07:10:44 AM ***** Eval results *****
06/29 07:10:44 AM   att_loss = 2.7748541226793955
06/29 07:10:44 AM   cls_loss = 0.0
06/29 07:10:44 AM   global_step = 24999
06/29 07:10:44 AM   loss = 3.6648576139621194
06/29 07:10:44 AM   rep_loss = 0.8900034979344458
06/29 07:10:44 AM ***** Save model *****
06/29 07:11:10 AM ***** Running evaluation *****
06/29 07:11:10 AM   Epoch = 2 iter 25199 step
06/29 07:11:10 AM   Num examples = 9815
06/29 07:11:10 AM   Batch size = 32
06/29 07:11:10 AM ***** Eval results *****
06/29 07:11:10 AM   att_loss = 2.7647672824482212
06/29 07:11:10 AM   cls_loss = 0.0
06/29 07:11:10 AM   global_step = 25199
06/29 07:11:10 AM   loss = 3.6539825787101523
06/29 07:11:10 AM   rep_loss = 0.8892152994372166
06/29 07:11:10 AM ***** Save model *****
06/29 07:11:36 AM ***** Running evaluation *****
06/29 07:11:36 AM   Epoch = 2 iter 25399 step
06/29 07:11:36 AM   Num examples = 9815
06/29 07:11:36 AM   Batch size = 32
06/29 07:11:36 AM ***** Eval results *****
06/29 07:11:36 AM   att_loss = 2.754616626641575
06/29 07:11:36 AM   cls_loss = 0.0
06/29 07:11:36 AM   global_step = 25399
06/29 07:11:36 AM   loss = 3.6430366484398324
06/29 07:11:36 AM   rep_loss = 0.8884200266667814
06/29 07:11:36 AM ***** Save model *****
06/29 07:12:02 AM ***** Running evaluation *****
06/29 07:12:02 AM   Epoch = 2 iter 25599 step
06/29 07:12:02 AM   Num examples = 9815
06/29 07:12:02 AM   Batch size = 32
06/29 07:12:02 AM ***** Eval results *****
06/29 07:12:02 AM   att_loss = 2.756980737200749
06/29 07:12:02 AM   cls_loss = 0.0
06/29 07:12:02 AM   global_step = 25599
06/29 07:12:02 AM   loss = 3.6453947576578765
06/29 07:12:02 AM   rep_loss = 0.8884140235585994
06/29 07:12:02 AM ***** Save model *****
06/29 07:12:29 AM ***** Running evaluation *****
06/29 07:12:29 AM   Epoch = 2 iter 25799 step
06/29 07:12:29 AM   Num examples = 9815
06/29 07:12:29 AM   Batch size = 32
06/29 07:12:29 AM ***** Eval results *****
06/29 07:12:29 AM   att_loss = 2.7509219572481505
06/29 07:12:29 AM   cls_loss = 0.0
06/29 07:12:29 AM   global_step = 25799
06/29 07:12:29 AM   loss = 3.638627344592754
06/29 07:12:29 AM   rep_loss = 0.8877053926080205
06/29 07:12:29 AM ***** Save model *****
06/29 07:12:57 AM ***** Running evaluation *****
06/29 07:12:57 AM   Epoch = 2 iter 25999 step
06/29 07:12:57 AM   Num examples = 9815
06/29 07:12:57 AM   Batch size = 32
06/29 07:12:57 AM ***** Eval results *****
06/29 07:12:57 AM   att_loss = 2.7503773979561412
06/29 07:12:57 AM   cls_loss = 0.0
06/29 07:12:57 AM   global_step = 25999
06/29 07:12:57 AM   loss = 3.6378958408523276
06/29 07:12:57 AM   rep_loss = 0.8875184464552833
06/29 07:12:57 AM ***** Save model *****
06/29 07:13:23 AM ***** Running evaluation *****
06/29 07:13:23 AM   Epoch = 2 iter 26199 step
06/29 07:13:23 AM   Num examples = 9815
06/29 07:13:23 AM   Batch size = 32
06/29 07:13:23 AM ***** Eval results *****
06/29 07:13:23 AM   att_loss = 2.7476957886062188
06/29 07:13:23 AM   cls_loss = 0.0
06/29 07:13:23 AM   global_step = 26199
06/29 07:13:23 AM   loss = 3.6348545499501204
06/29 07:13:23 AM   rep_loss = 0.8871587638978722
06/29 07:13:23 AM ***** Save model *****
06/29 07:13:49 AM ***** Running evaluation *****
06/29 07:13:49 AM   Epoch = 2 iter 26399 step
06/29 07:13:49 AM   Num examples = 9815
06/29 07:13:49 AM   Batch size = 32
06/29 07:13:49 AM ***** Eval results *****
06/29 07:13:49 AM   att_loss = 2.750556892968662
06/29 07:13:49 AM   cls_loss = 0.0
06/29 07:13:49 AM   global_step = 26399
06/29 07:13:49 AM   loss = 3.6375273780021606
06/29 07:13:49 AM   rep_loss = 0.8869704875370862
06/29 07:13:49 AM ***** Save model *****
06/29 07:14:18 AM ***** Running evaluation *****
06/29 07:14:18 AM   Epoch = 2 iter 26599 step
06/29 07:14:18 AM   Num examples = 9815
06/29 07:14:18 AM   Batch size = 32
06/29 07:14:18 AM ***** Eval results *****
06/29 07:14:18 AM   att_loss = 2.751378532689233
06/29 07:14:18 AM   cls_loss = 0.0
06/29 07:14:18 AM   global_step = 26599
06/29 07:14:18 AM   loss = 3.6380173225801546
06/29 07:14:18 AM   rep_loss = 0.8866387919482527
06/29 07:14:18 AM ***** Save model *****
06/29 07:14:44 AM ***** Running evaluation *****
06/29 07:14:44 AM   Epoch = 2 iter 26799 step
06/29 07:14:44 AM   Num examples = 9815
06/29 07:14:44 AM   Batch size = 32
06/29 07:14:44 AM ***** Eval results *****
06/29 07:14:44 AM   att_loss = 2.7524715432774243
06/29 07:14:44 AM   cls_loss = 0.0
06/29 07:14:44 AM   global_step = 26799
06/29 07:14:44 AM   loss = 3.6389483974526082
06/29 07:14:44 AM   rep_loss = 0.8864768562614785
06/29 07:14:44 AM ***** Save model *****
06/29 07:15:11 AM ***** Running evaluation *****
06/29 07:15:11 AM   Epoch = 2 iter 26999 step
06/29 07:15:11 AM   Num examples = 9815
06/29 07:15:11 AM   Batch size = 32
06/29 07:15:11 AM ***** Eval results *****
06/29 07:15:11 AM   att_loss = 2.755076071815273
06/29 07:15:11 AM   cls_loss = 0.0
06/29 07:15:11 AM   global_step = 26999
06/29 07:15:11 AM   loss = 3.641475531062218
06/29 07:15:11 AM   rep_loss = 0.8863994608965646
06/29 07:15:11 AM ***** Save model *****
06/29 07:15:37 AM ***** Running evaluation *****
06/29 07:15:37 AM   Epoch = 2 iter 27199 step
06/29 07:15:37 AM   Num examples = 9815
06/29 07:15:37 AM   Batch size = 32
06/29 07:15:37 AM ***** Eval results *****
06/29 07:15:37 AM   att_loss = 2.7537577241535782
06/29 07:15:37 AM   cls_loss = 0.0
06/29 07:15:37 AM   global_step = 27199
06/29 07:15:37 AM   loss = 3.6398368737820532
06/29 07:15:37 AM   rep_loss = 0.8860791511987895
06/29 07:15:37 AM ***** Save model *****
06/29 07:16:04 AM ***** Running evaluation *****
06/29 07:16:04 AM   Epoch = 2 iter 27399 step
06/29 07:16:04 AM   Num examples = 9815
06/29 07:16:04 AM   Batch size = 32
06/29 07:16:04 AM ***** Eval results *****
06/29 07:16:04 AM   att_loss = 2.7530314190053087
06/29 07:16:04 AM   cls_loss = 0.0
06/29 07:16:04 AM   global_step = 27399
06/29 07:16:04 AM   loss = 3.638985786397932
06/29 07:16:04 AM   rep_loss = 0.8859543682479926
06/29 07:16:04 AM ***** Save model *****
06/29 07:16:33 AM ***** Running evaluation *****
06/29 07:16:33 AM   Epoch = 2 iter 27599 step
06/29 07:16:33 AM   Num examples = 9815
06/29 07:16:33 AM   Batch size = 32
06/29 07:16:33 AM ***** Eval results *****
06/29 07:16:33 AM   att_loss = 2.75099246576794
06/29 07:16:33 AM   cls_loss = 0.0
06/29 07:16:33 AM   global_step = 27599
06/29 07:16:33 AM   loss = 3.6366907757093676
06/29 07:16:33 AM   rep_loss = 0.8856983113842616
06/29 07:16:33 AM ***** Save model *****
06/29 07:16:59 AM ***** Running evaluation *****
06/29 07:16:59 AM   Epoch = 2 iter 27799 step
06/29 07:16:59 AM   Num examples = 9815
06/29 07:16:59 AM   Batch size = 32
06/29 07:16:59 AM ***** Eval results *****
06/29 07:16:59 AM   att_loss = 2.749969327856069
06/29 07:16:59 AM   cls_loss = 0.0
06/29 07:16:59 AM   global_step = 27799
06/29 07:16:59 AM   loss = 3.6354686252024777
06/29 07:16:59 AM   rep_loss = 0.8854992992496579
06/29 07:16:59 AM ***** Save model *****
06/29 07:17:26 AM ***** Running evaluation *****
06/29 07:17:26 AM   Epoch = 2 iter 27999 step
06/29 07:17:26 AM   Num examples = 9815
06/29 07:17:26 AM   Batch size = 32
06/29 07:17:26 AM ***** Eval results *****
06/29 07:17:26 AM   att_loss = 2.747413781325804
06/29 07:17:26 AM   cls_loss = 0.0
06/29 07:17:26 AM   global_step = 27999
06/29 07:17:26 AM   loss = 3.63255391522298
06/29 07:17:26 AM   rep_loss = 0.8851401355178983
06/29 07:17:26 AM ***** Save model *****
06/29 07:17:54 AM ***** Running evaluation *****
06/29 07:17:54 AM   Epoch = 2 iter 28199 step
06/29 07:17:54 AM   Num examples = 9815
06/29 07:17:54 AM   Batch size = 32
06/29 07:17:54 AM ***** Eval results *****
06/29 07:17:54 AM   att_loss = 2.7462497250382483
06/29 07:17:54 AM   cls_loss = 0.0
06/29 07:17:54 AM   global_step = 28199
06/29 07:17:54 AM   loss = 3.6310839883153934
06/29 07:17:54 AM   rep_loss = 0.8848342651026087
06/29 07:17:54 AM ***** Save model *****
06/29 07:18:21 AM ***** Running evaluation *****
06/29 07:18:21 AM   Epoch = 2 iter 28399 step
06/29 07:18:21 AM   Num examples = 9815
06/29 07:18:21 AM   Batch size = 32
06/29 07:18:21 AM ***** Eval results *****
06/29 07:18:21 AM   att_loss = 2.7457945226912117
06/29 07:18:21 AM   cls_loss = 0.0
06/29 07:18:21 AM   global_step = 28399
06/29 07:18:21 AM   loss = 3.6303600369879456
06/29 07:18:21 AM   rep_loss = 0.8845655157339212
06/29 07:18:21 AM ***** Save model *****
06/29 07:18:47 AM ***** Running evaluation *****
06/29 07:18:47 AM   Epoch = 2 iter 28599 step
06/29 07:18:47 AM   Num examples = 9815
06/29 07:18:47 AM   Batch size = 32
06/29 07:18:47 AM ***** Eval results *****
06/29 07:18:47 AM   att_loss = 2.7455480297945214
06/29 07:18:47 AM   cls_loss = 0.0
06/29 07:18:47 AM   global_step = 28599
06/29 07:18:47 AM   loss = 3.629901841910919
06/29 07:18:47 AM   rep_loss = 0.8843538136296535
06/29 07:18:47 AM ***** Save model *****
06/29 07:19:13 AM ***** Running evaluation *****
06/29 07:19:13 AM   Epoch = 2 iter 28799 step
06/29 07:19:13 AM   Num examples = 9815
06/29 07:19:13 AM   Batch size = 32
06/29 07:19:13 AM ***** Eval results *****
06/29 07:19:13 AM   att_loss = 2.7436256665760066
06/29 07:19:13 AM   cls_loss = 0.0
06/29 07:19:13 AM   global_step = 28799
06/29 07:19:13 AM   loss = 3.627639403050848
06/29 07:19:13 AM   rep_loss = 0.8840137374689525
06/29 07:19:13 AM ***** Save model *****
06/29 07:19:40 AM ***** Running evaluation *****
06/29 07:19:40 AM   Epoch = 2 iter 28999 step
06/29 07:19:40 AM   Num examples = 9815
06/29 07:19:40 AM   Batch size = 32
06/29 07:19:40 AM ***** Eval results *****
06/29 07:19:40 AM   att_loss = 2.741967838709735
06/29 07:19:40 AM   cls_loss = 0.0
06/29 07:19:40 AM   global_step = 28999
06/29 07:19:40 AM   loss = 3.62567817990973
06/29 07:19:40 AM   rep_loss = 0.8837103423500959
06/29 07:19:40 AM ***** Save model *****
06/29 07:20:10 AM ***** Running evaluation *****
06/29 07:20:10 AM   Epoch = 2 iter 29199 step
06/29 07:20:10 AM   Num examples = 9815
06/29 07:20:10 AM   Batch size = 32
06/29 07:20:10 AM ***** Eval results *****
06/29 07:20:10 AM   att_loss = 2.7409885773362843
06/29 07:20:10 AM   cls_loss = 0.0
06/29 07:20:10 AM   global_step = 29199
06/29 07:20:10 AM   loss = 3.6245168875746905
06/29 07:20:10 AM   rep_loss = 0.8835283111855275
06/29 07:20:10 AM ***** Save model *****
06/29 07:20:37 AM ***** Running evaluation *****
06/29 07:20:37 AM   Epoch = 2 iter 29399 step
06/29 07:20:37 AM   Num examples = 9815
06/29 07:20:37 AM   Batch size = 32
06/29 07:20:37 AM ***** Eval results *****
06/29 07:20:37 AM   att_loss = 2.7382504305820885
06/29 07:20:37 AM   cls_loss = 0.0
06/29 07:20:37 AM   global_step = 29399
06/29 07:20:37 AM   loss = 3.621382831177251
06/29 07:20:37 AM   rep_loss = 0.883132401441924
06/29 07:20:37 AM ***** Save model *****
06/29 07:21:04 AM ***** Running evaluation *****
06/29 07:21:04 AM   Epoch = 2 iter 29599 step
06/29 07:21:04 AM   Num examples = 9815
06/29 07:21:04 AM   Batch size = 32
06/29 07:21:04 AM ***** Eval results *****
06/29 07:21:04 AM   att_loss = 2.737743037313205
06/29 07:21:04 AM   cls_loss = 0.0
06/29 07:21:04 AM   global_step = 29599
06/29 07:21:04 AM   loss = 3.620698413760242
06/29 07:21:04 AM   rep_loss = 0.8829553773663886
06/29 07:21:04 AM ***** Save model *****
06/29 07:21:32 AM ***** Running evaluation *****
06/29 07:21:32 AM   Epoch = 2 iter 29799 step
06/29 07:21:32 AM   Num examples = 9815
06/29 07:21:32 AM   Batch size = 32
06/29 07:21:32 AM ***** Eval results *****
06/29 07:21:32 AM   att_loss = 2.7372446585136925
06/29 07:21:32 AM   cls_loss = 0.0
06/29 07:21:32 AM   global_step = 29799
06/29 07:21:32 AM   loss = 3.6199968484320157
06/29 07:21:32 AM   rep_loss = 0.8827521908367136
06/29 07:21:32 AM ***** Save model *****
06/29 07:21:58 AM ***** Running evaluation *****
06/29 07:21:58 AM   Epoch = 2 iter 29999 step
06/29 07:21:58 AM   Num examples = 9815
06/29 07:21:58 AM   Batch size = 32
06/29 07:21:58 AM ***** Eval results *****
06/29 07:21:58 AM   att_loss = 2.7364553856460825
06/29 07:21:58 AM   cls_loss = 0.0
06/29 07:21:58 AM   global_step = 29999
06/29 07:21:58 AM   loss = 3.619003951036168
06/29 07:21:58 AM   rep_loss = 0.8825485664714228
06/29 07:21:58 AM ***** Save model *****
06/29 07:22:25 AM ***** Running evaluation *****
06/29 07:22:25 AM   Epoch = 2 iter 30199 step
06/29 07:22:25 AM   Num examples = 9815
06/29 07:22:25 AM   Batch size = 32
06/29 07:22:25 AM ***** Eval results *****
06/29 07:22:25 AM   att_loss = 2.7367579694432336
06/29 07:22:25 AM   cls_loss = 0.0
06/29 07:22:25 AM   global_step = 30199
06/29 07:22:25 AM   loss = 3.6192073747002027
06/29 07:22:25 AM   rep_loss = 0.8824494065318783
06/29 07:22:25 AM ***** Save model *****
06/29 07:22:52 AM ***** Running evaluation *****
06/29 07:22:52 AM   Epoch = 2 iter 30399 step
06/29 07:22:52 AM   Num examples = 9815
06/29 07:22:52 AM   Batch size = 32
06/29 07:22:52 AM ***** Eval results *****
06/29 07:22:52 AM   att_loss = 2.7354736035240985
06/29 07:22:52 AM   cls_loss = 0.0
06/29 07:22:52 AM   global_step = 30399
06/29 07:22:52 AM   loss = 3.617658372012466
06/29 07:22:52 AM   rep_loss = 0.8821847694755028
06/29 07:22:52 AM ***** Save model *****
06/29 07:23:18 AM ***** Running evaluation *****
06/29 07:23:18 AM   Epoch = 2 iter 30599 step
06/29 07:23:18 AM   Num examples = 9815
06/29 07:23:18 AM   Batch size = 32
06/29 07:23:18 AM ***** Eval results *****
06/29 07:23:18 AM   att_loss = 2.734429594134859
06/29 07:23:18 AM   cls_loss = 0.0
06/29 07:23:18 AM   global_step = 30599
06/29 07:23:18 AM   loss = 3.616395391251991
06/29 07:23:18 AM   rep_loss = 0.8819657980027875
06/29 07:23:18 AM ***** Save model *****
06/29 07:23:46 AM ***** Running evaluation *****
06/29 07:23:46 AM   Epoch = 2 iter 30799 step
06/29 07:23:46 AM   Num examples = 9815
06/29 07:23:46 AM   Batch size = 32
06/29 07:23:46 AM ***** Eval results *****
06/29 07:23:46 AM   att_loss = 2.7334366126888874
06/29 07:23:46 AM   cls_loss = 0.0
06/29 07:23:46 AM   global_step = 30799
06/29 07:23:46 AM   loss = 3.6151641834957715
06/29 07:23:46 AM   rep_loss = 0.8817275715403917
06/29 07:23:46 AM ***** Save model *****
06/29 07:24:13 AM ***** Running evaluation *****
06/29 07:24:13 AM   Epoch = 2 iter 30999 step
06/29 07:24:13 AM   Num examples = 9815
06/29 07:24:13 AM   Batch size = 32
06/29 07:24:13 AM ***** Eval results *****
06/29 07:24:13 AM   att_loss = 2.7323067661444616
06/29 07:24:13 AM   cls_loss = 0.0
06/29 07:24:13 AM   global_step = 30999
06/29 07:24:13 AM   loss = 3.6137686709566013
06/29 07:24:13 AM   rep_loss = 0.8814619058737061
06/29 07:24:13 AM ***** Save model *****
06/29 07:24:39 AM ***** Running evaluation *****
06/29 07:24:39 AM   Epoch = 2 iter 31199 step
06/29 07:24:39 AM   Num examples = 9815
06/29 07:24:39 AM   Batch size = 32
06/29 07:24:39 AM ***** Eval results *****
06/29 07:24:39 AM   att_loss = 2.732148832595794
06/29 07:24:39 AM   cls_loss = 0.0
06/29 07:24:39 AM   global_step = 31199
06/29 07:24:39 AM   loss = 3.613430132929656
06/29 07:24:39 AM   rep_loss = 0.8812813014530717
06/29 07:24:39 AM ***** Save model *****
06/29 07:25:08 AM ***** Running evaluation *****
06/29 07:25:08 AM   Epoch = 2 iter 31399 step
06/29 07:25:08 AM   Num examples = 9815
06/29 07:25:08 AM   Batch size = 32
06/29 07:25:08 AM ***** Eval results *****
06/29 07:25:08 AM   att_loss = 2.7314439047455563
06/29 07:25:08 AM   cls_loss = 0.0
06/29 07:25:08 AM   global_step = 31399
06/29 07:25:08 AM   loss = 3.6125364126609054
06/29 07:25:08 AM   rep_loss = 0.8810925090801478
06/29 07:25:08 AM ***** Save model *****
06/29 07:25:34 AM ***** Running evaluation *****
06/29 07:25:34 AM   Epoch = 2 iter 31599 step
06/29 07:25:34 AM   Num examples = 9815
06/29 07:25:34 AM   Batch size = 32
06/29 07:25:34 AM ***** Eval results *****
06/29 07:25:34 AM   att_loss = 2.730957475890346
06/29 07:25:34 AM   cls_loss = 0.0
06/29 07:25:34 AM   global_step = 31599
06/29 07:25:34 AM   loss = 3.6118602692548794
06/29 07:25:34 AM   rep_loss = 0.880902794749706
06/29 07:25:34 AM ***** Save model *****
06/29 07:26:00 AM ***** Running evaluation *****
06/29 07:26:00 AM   Epoch = 2 iter 31799 step
06/29 07:26:00 AM   Num examples = 9815
06/29 07:26:00 AM   Batch size = 32
06/29 07:26:00 AM ***** Eval results *****
06/29 07:26:00 AM   att_loss = 2.7298221864105012
06/29 07:26:00 AM   cls_loss = 0.0
06/29 07:26:00 AM   global_step = 31799
06/29 07:26:00 AM   loss = 3.610419207669264
06/29 07:26:00 AM   rep_loss = 0.8805970226468274
06/29 07:26:00 AM ***** Save model *****
06/29 07:26:26 AM ***** Running evaluation *****
06/29 07:26:26 AM   Epoch = 2 iter 31999 step
06/29 07:26:26 AM   Num examples = 9815
06/29 07:26:26 AM   Batch size = 32
06/29 07:26:26 AM ***** Eval results *****
06/29 07:26:26 AM   att_loss = 2.7298366778239305
06/29 07:26:26 AM   cls_loss = 0.0
06/29 07:26:26 AM   global_step = 31999
06/29 07:26:26 AM   loss = 3.6102541000094575
06/29 07:26:26 AM   rep_loss = 0.880417423688232
06/29 07:26:26 AM ***** Save model *****
06/29 07:26:52 AM ***** Running evaluation *****
06/29 07:26:52 AM   Epoch = 2 iter 32199 step
06/29 07:26:52 AM   Num examples = 9815
06/29 07:26:52 AM   Batch size = 32
06/29 07:26:52 AM ***** Eval results *****
06/29 07:26:52 AM   att_loss = 2.7305620078148753
06/29 07:26:52 AM   cls_loss = 0.0
06/29 07:26:52 AM   global_step = 32199
06/29 07:26:52 AM   loss = 3.6108509607129484
06/29 07:26:52 AM   rep_loss = 0.8802889543537435
06/29 07:26:52 AM ***** Save model *****
06/29 07:27:21 AM ***** Running evaluation *****
06/29 07:27:21 AM   Epoch = 2 iter 32399 step
06/29 07:27:21 AM   Num examples = 9815
06/29 07:27:21 AM   Batch size = 32
06/29 07:27:21 AM ***** Eval results *****
06/29 07:27:21 AM   att_loss = 2.729954872814711
06/29 07:27:21 AM   cls_loss = 0.0
06/29 07:27:21 AM   global_step = 32399
06/29 07:27:21 AM   loss = 3.610012694777947
06/29 07:27:21 AM   rep_loss = 0.8800578234121972
06/29 07:27:21 AM ***** Save model *****
06/29 07:27:47 AM ***** Running evaluation *****
06/29 07:27:47 AM   Epoch = 2 iter 32599 step
06/29 07:27:47 AM   Num examples = 9815
06/29 07:27:47 AM   Batch size = 32
06/29 07:27:47 AM ***** Eval results *****
06/29 07:27:47 AM   att_loss = 2.7292549260070693
06/29 07:27:47 AM   cls_loss = 0.0
06/29 07:27:47 AM   global_step = 32599
06/29 07:27:47 AM   loss = 3.609148927520282
06/29 07:27:47 AM   rep_loss = 0.8798940030445721
06/29 07:27:47 AM ***** Save model *****
06/29 07:28:13 AM ***** Running evaluation *****
06/29 07:28:13 AM   Epoch = 2 iter 32799 step
06/29 07:28:13 AM   Num examples = 9815
06/29 07:28:13 AM   Batch size = 32
06/29 07:28:13 AM ***** Eval results *****
06/29 07:28:13 AM   att_loss = 2.7292593066161346
06/29 07:28:13 AM   cls_loss = 0.0
06/29 07:28:13 AM   global_step = 32799
06/29 07:28:13 AM   loss = 3.6089783478580144
06/29 07:28:13 AM   rep_loss = 0.8797190428949577
06/29 07:28:13 AM ***** Save model *****
06/29 07:28:41 AM ***** Running evaluation *****
06/29 07:28:41 AM   Epoch = 2 iter 32999 step
06/29 07:28:41 AM   Num examples = 9815
06/29 07:28:41 AM   Batch size = 32
06/29 07:28:41 AM ***** Eval results *****
06/29 07:28:41 AM   att_loss = 2.728367545707042
06/29 07:28:41 AM   cls_loss = 0.0
06/29 07:28:41 AM   global_step = 32999
06/29 07:28:41 AM   loss = 3.6078622226697044
06/29 07:28:41 AM   rep_loss = 0.8794946787739893
06/29 07:28:41 AM ***** Save model *****
06/29 07:29:07 AM ***** Running evaluation *****
06/29 07:29:07 AM   Epoch = 2 iter 33199 step
06/29 07:29:07 AM   Num examples = 9815
06/29 07:29:07 AM   Batch size = 32
06/29 07:29:07 AM ***** Eval results *****
06/29 07:29:07 AM   att_loss = 2.7275908170815524
06/29 07:29:07 AM   cls_loss = 0.0
06/29 07:29:07 AM   global_step = 33199
06/29 07:29:07 AM   loss = 3.6068453064991557
06/29 07:29:07 AM   rep_loss = 0.8792544910700365
06/29 07:29:07 AM ***** Save model *****
06/29 07:29:33 AM ***** Running evaluation *****
06/29 07:29:33 AM   Epoch = 2 iter 33399 step
06/29 07:29:33 AM   Num examples = 9815
06/29 07:29:33 AM   Batch size = 32
06/29 07:29:33 AM ***** Eval results *****
06/29 07:29:33 AM   att_loss = 2.7276557256745555
06/29 07:29:33 AM   cls_loss = 0.0
06/29 07:29:33 AM   global_step = 33399
06/29 07:29:33 AM   loss = 3.6067424791182514
06/29 07:29:33 AM   rep_loss = 0.8790867551059234
06/29 07:29:33 AM ***** Save model *****
06/29 07:30:00 AM ***** Running evaluation *****
06/29 07:30:00 AM   Epoch = 2 iter 33599 step
06/29 07:30:00 AM   Num examples = 9815
06/29 07:30:00 AM   Batch size = 32
06/29 07:30:00 AM ***** Eval results *****
06/29 07:30:00 AM   att_loss = 2.7270194204540408
06/29 07:30:00 AM   cls_loss = 0.0
06/29 07:30:00 AM   global_step = 33599
06/29 07:30:00 AM   loss = 3.6058877959371967
06/29 07:30:00 AM   rep_loss = 0.8788683769375701
06/29 07:30:00 AM ***** Save model *****
06/29 07:30:26 AM ***** Running evaluation *****
06/29 07:30:26 AM   Epoch = 2 iter 33799 step
06/29 07:30:26 AM   Num examples = 9815
06/29 07:30:26 AM   Batch size = 32
06/29 07:30:26 AM ***** Eval results *****
06/29 07:30:26 AM   att_loss = 2.7261701515146655
06/29 07:30:26 AM   cls_loss = 0.0
06/29 07:30:26 AM   global_step = 33799
06/29 07:30:26 AM   loss = 3.604837294980647
06/29 07:30:26 AM   rep_loss = 0.8786671448889724
06/29 07:30:26 AM ***** Save model *****
06/29 07:30:54 AM ***** Running evaluation *****
06/29 07:30:54 AM   Epoch = 2 iter 33999 step
06/29 07:30:54 AM   Num examples = 9815
06/29 07:30:54 AM   Batch size = 32
06/29 07:30:54 AM ***** Eval results *****
06/29 07:30:54 AM   att_loss = 2.7259667354342523
06/29 07:30:54 AM   cls_loss = 0.0
06/29 07:30:54 AM   global_step = 33999
06/29 07:30:54 AM   loss = 3.604468297968458
06/29 07:30:54 AM   rep_loss = 0.8785015637380219
06/29 07:30:54 AM ***** Save model *****
06/29 07:31:20 AM ***** Running evaluation *****
06/29 07:31:20 AM   Epoch = 2 iter 34199 step
06/29 07:31:20 AM   Num examples = 9815
06/29 07:31:20 AM   Batch size = 32
06/29 07:31:20 AM ***** Eval results *****
06/29 07:31:20 AM   att_loss = 2.7250236623514583
06/29 07:31:20 AM   cls_loss = 0.0
06/29 07:31:20 AM   global_step = 34199
06/29 07:31:20 AM   loss = 3.6032865125964837
06/29 07:31:20 AM   rep_loss = 0.8782628512757775
06/29 07:31:20 AM ***** Save model *****
06/29 07:31:47 AM ***** Running evaluation *****
06/29 07:31:47 AM   Epoch = 2 iter 34399 step
06/29 07:31:47 AM   Num examples = 9815
06/29 07:31:47 AM   Batch size = 32
06/29 07:31:47 AM ***** Eval results *****
06/29 07:31:47 AM   att_loss = 2.724030824586563
06/29 07:31:47 AM   cls_loss = 0.0
06/29 07:31:47 AM   global_step = 34399
06/29 07:31:47 AM   loss = 3.6020367758697605
06/29 07:31:47 AM   rep_loss = 0.8780059523293173
06/29 07:31:47 AM ***** Save model *****
06/29 07:32:15 AM ***** Running evaluation *****
06/29 07:32:15 AM   Epoch = 2 iter 34599 step
06/29 07:32:15 AM   Num examples = 9815
06/29 07:32:15 AM   Batch size = 32
06/29 07:32:15 AM ***** Eval results *****
06/29 07:32:15 AM   att_loss = 2.7225232419121794
06/29 07:32:15 AM   cls_loss = 0.0
06/29 07:32:15 AM   global_step = 34599
06/29 07:32:15 AM   loss = 3.600259264077085
06/29 07:32:15 AM   rep_loss = 0.877736023160588
06/29 07:32:15 AM ***** Save model *****
06/29 07:32:41 AM ***** Running evaluation *****
06/29 07:32:41 AM   Epoch = 2 iter 34799 step
06/29 07:32:41 AM   Num examples = 9815
06/29 07:32:41 AM   Batch size = 32
06/29 07:32:41 AM ***** Eval results *****
06/29 07:32:41 AM   att_loss = 2.7220882984633517
06/29 07:32:41 AM   cls_loss = 0.0
06/29 07:32:41 AM   global_step = 34799
06/29 07:32:41 AM   loss = 3.5996398430673935
06/29 07:32:41 AM   rep_loss = 0.8775515453362426
06/29 07:32:41 AM ***** Save model *****
06/29 07:33:07 AM ***** Running evaluation *****
06/29 07:33:07 AM   Epoch = 2 iter 34999 step
06/29 07:33:07 AM   Num examples = 9815
06/29 07:33:07 AM   Batch size = 32
06/29 07:33:07 AM ***** Eval results *****
06/29 07:33:07 AM   att_loss = 2.721784430513695
06/29 07:33:07 AM   cls_loss = 0.0
06/29 07:33:07 AM   global_step = 34999
06/29 07:33:07 AM   loss = 3.5991521539430016
06/29 07:33:07 AM   rep_loss = 0.8773677241874035
06/29 07:33:07 AM ***** Save model *****
06/29 07:33:33 AM ***** Running evaluation *****
06/29 07:33:33 AM   Epoch = 2 iter 35199 step
06/29 07:33:33 AM   Num examples = 9815
06/29 07:33:33 AM   Batch size = 32
06/29 07:33:33 AM ***** Eval results *****
06/29 07:33:33 AM   att_loss = 2.7212363818667895
06/29 07:33:33 AM   cls_loss = 0.0
06/29 07:33:33 AM   global_step = 35199
06/29 07:33:33 AM   loss = 3.5984082550182346
06/29 07:33:33 AM   rep_loss = 0.8771718737219314
06/29 07:33:33 AM ***** Save model *****
06/29 07:33:59 AM ***** Running evaluation *****
06/29 07:33:59 AM   Epoch = 2 iter 35399 step
06/29 07:33:59 AM   Num examples = 9815
06/29 07:33:59 AM   Batch size = 32
06/29 07:33:59 AM ***** Eval results *****
06/29 07:33:59 AM   att_loss = 2.7203709859594167
06/29 07:33:59 AM   cls_loss = 0.0
06/29 07:33:59 AM   global_step = 35399
06/29 07:33:59 AM   loss = 3.597324190915394
06/29 07:33:59 AM   rep_loss = 0.8769532054171352
06/29 07:33:59 AM ***** Save model *****
06/29 07:34:28 AM ***** Running evaluation *****
06/29 07:34:28 AM   Epoch = 2 iter 35599 step
06/29 07:34:28 AM   Num examples = 9815
06/29 07:34:28 AM   Batch size = 32
06/29 07:34:28 AM ***** Eval results *****
06/29 07:34:28 AM   att_loss = 2.7207287993409097
06/29 07:34:28 AM   cls_loss = 0.0
06/29 07:34:28 AM   global_step = 35599
06/29 07:34:28 AM   loss = 3.5975428196818293
06/29 07:34:28 AM   rep_loss = 0.8768140209554559
06/29 07:34:28 AM ***** Save model *****
06/29 07:34:54 AM ***** Running evaluation *****
06/29 07:34:54 AM   Epoch = 2 iter 35799 step
06/29 07:34:54 AM   Num examples = 9815
06/29 07:34:54 AM   Batch size = 32
06/29 07:34:54 AM ***** Eval results *****
06/29 07:34:54 AM   att_loss = 2.719568423885133
06/29 07:34:54 AM   cls_loss = 0.0
06/29 07:34:54 AM   global_step = 35799
06/29 07:34:54 AM   loss = 3.5961166315162605
06/29 07:34:54 AM   rep_loss = 0.8765482082294509
06/29 07:34:54 AM ***** Save model *****
06/29 07:35:20 AM ***** Running evaluation *****
06/29 07:35:20 AM   Epoch = 2 iter 35999 step
06/29 07:35:20 AM   Num examples = 9815
06/29 07:35:20 AM   Batch size = 32
06/29 07:35:20 AM ***** Eval results *****
06/29 07:35:20 AM   att_loss = 2.719663411886101
06/29 07:35:20 AM   cls_loss = 0.0
06/29 07:35:20 AM   global_step = 35999
06/29 07:35:20 AM   loss = 3.596076196261993
06/29 07:35:20 AM   rep_loss = 0.8764127849585683
06/29 07:35:20 AM ***** Save model *****
06/29 07:35:48 AM ***** Running evaluation *****
06/29 07:35:48 AM   Epoch = 2 iter 36199 step
06/29 07:35:48 AM   Num examples = 9815
06/29 07:35:48 AM   Batch size = 32
06/29 07:35:48 AM ***** Eval results *****
06/29 07:35:48 AM   att_loss = 2.7192266604457966
06/29 07:35:48 AM   cls_loss = 0.0
06/29 07:35:48 AM   global_step = 36199
06/29 07:35:48 AM   loss = 3.595454240771789
06/29 07:35:48 AM   rep_loss = 0.8762275808577658
06/29 07:35:48 AM ***** Save model *****
06/29 07:36:14 AM ***** Running evaluation *****
06/29 07:36:14 AM   Epoch = 2 iter 36399 step
06/29 07:36:14 AM   Num examples = 9815
06/29 07:36:14 AM   Batch size = 32
06/29 07:36:14 AM ***** Eval results *****
06/29 07:36:14 AM   att_loss = 2.719032261960169
06/29 07:36:14 AM   cls_loss = 0.0
06/29 07:36:14 AM   global_step = 36399
06/29 07:36:14 AM   loss = 3.5951117403925275
06/29 07:36:14 AM   rep_loss = 0.8760794788043536
06/29 07:36:14 AM ***** Save model *****
06/29 07:36:41 AM ***** Running evaluation *****
06/29 07:36:41 AM   Epoch = 2 iter 36599 step
06/29 07:36:41 AM   Num examples = 9815
06/29 07:36:41 AM   Batch size = 32
06/29 07:36:41 AM ***** Eval results *****
06/29 07:36:41 AM   att_loss = 2.7183172964403126
06/29 07:36:41 AM   cls_loss = 0.0
06/29 07:36:41 AM   global_step = 36599
06/29 07:36:41 AM   loss = 3.5942115223485853
06/29 07:36:41 AM   rep_loss = 0.8758942262740973
06/29 07:36:41 AM ***** Save model *****
06/29 07:37:06 AM ***** Running evaluation *****
06/29 07:37:06 AM   Epoch = 2 iter 36799 step
06/29 07:37:06 AM   Num examples = 9815
06/29 07:37:06 AM   Batch size = 32
06/29 07:37:06 AM ***** Eval results *****
06/29 07:37:06 AM   att_loss = 2.717196631511331
06/29 07:37:06 AM   cls_loss = 0.0
06/29 07:37:06 AM   global_step = 36799
06/29 07:37:06 AM   loss = 3.5928511646800145
06/29 07:37:06 AM   rep_loss = 0.8756545336403854
06/29 07:37:06 AM ***** Save model *****
06/29 07:37:33 AM ***** Running evaluation *****
06/29 07:37:33 AM   Epoch = 3 iter 36999 step
06/29 07:37:33 AM   Num examples = 9815
06/29 07:37:33 AM   Batch size = 32
06/29 07:37:33 AM ***** Eval results *****
06/29 07:37:33 AM   att_loss = 2.6617097354704335
06/29 07:37:33 AM   cls_loss = 0.0
06/29 07:37:33 AM   global_step = 36999
06/29 07:37:33 AM   loss = 3.5238006512324014
06/29 07:37:33 AM   rep_loss = 0.8620909122369622
06/29 07:37:33 AM ***** Save model *****
06/29 07:38:01 AM ***** Running evaluation *****
06/29 07:38:01 AM   Epoch = 3 iter 37199 step
06/29 07:38:01 AM   Num examples = 9815
06/29 07:38:01 AM   Batch size = 32
06/29 07:38:01 AM ***** Eval results *****
06/29 07:38:01 AM   att_loss = 2.6680057573812612
06/29 07:38:01 AM   cls_loss = 0.0
06/29 07:38:01 AM   global_step = 37199
06/29 07:38:01 AM   loss = 3.529835293330059
06/29 07:38:01 AM   rep_loss = 0.8618295345590522
06/29 07:38:01 AM ***** Save model *****
06/29 07:38:27 AM ***** Running evaluation *****
06/29 07:38:27 AM   Epoch = 3 iter 37399 step
06/29 07:38:27 AM   Num examples = 9815
06/29 07:38:27 AM   Batch size = 32
06/29 07:38:27 AM ***** Eval results *****
06/29 07:38:27 AM   att_loss = 2.664661338304904
06/29 07:38:27 AM   cls_loss = 0.0
06/29 07:38:27 AM   global_step = 37399
06/29 07:38:27 AM   loss = 3.5265502229892354
06/29 07:38:27 AM   rep_loss = 0.8618888873289062
06/29 07:38:27 AM ***** Save model *****
06/29 07:38:53 AM ***** Running evaluation *****
06/29 07:38:53 AM   Epoch = 3 iter 37599 step
06/29 07:38:53 AM   Num examples = 9815
06/29 07:38:53 AM   Batch size = 32
06/29 07:38:53 AM ***** Eval results *****
06/29 07:38:53 AM   att_loss = 2.6655826665669604
06/29 07:38:53 AM   cls_loss = 0.0
06/29 07:38:53 AM   global_step = 37599
06/29 07:38:53 AM   loss = 3.527407327377766
06/29 07:38:53 AM   rep_loss = 0.8618246640716194
06/29 07:38:53 AM ***** Save model *****
06/29 07:39:21 AM ***** Running evaluation *****
06/29 07:39:21 AM   Epoch = 3 iter 37799 step
06/29 07:39:21 AM   Num examples = 9815
06/29 07:39:21 AM   Batch size = 32
06/29 07:39:21 AM ***** Eval results *****
06/29 07:39:21 AM   att_loss = 2.672114101674929
06/29 07:39:21 AM   cls_loss = 0.0
06/29 07:39:21 AM   global_step = 37799
06/29 07:39:21 AM   loss = 3.534280337378171
06/29 07:39:21 AM   rep_loss = 0.8621662393302995
06/29 07:39:21 AM ***** Save model *****
06/29 07:39:48 AM ***** Running evaluation *****
06/29 07:39:48 AM   Epoch = 3 iter 37999 step
06/29 07:39:48 AM   Num examples = 9815
06/29 07:39:48 AM   Batch size = 32
06/29 07:39:48 AM ***** Eval results *****
06/29 07:39:48 AM   att_loss = 2.6720538229805624
06/29 07:39:48 AM   cls_loss = 0.0
06/29 07:39:48 AM   global_step = 37999
06/29 07:39:48 AM   loss = 3.533901054380716
06/29 07:39:48 AM   rep_loss = 0.8618472356217306
06/29 07:39:48 AM ***** Save model *****
06/29 07:40:15 AM ***** Running evaluation *****
06/29 07:40:15 AM   Epoch = 3 iter 38199 step
06/29 07:40:15 AM   Num examples = 9815
06/29 07:40:15 AM   Batch size = 32
06/29 07:40:15 AM ***** Eval results *****
06/29 07:40:15 AM   att_loss = 2.6666561230952603
06/29 07:40:15 AM   cls_loss = 0.0
06/29 07:40:15 AM   global_step = 38199
06/29 07:40:15 AM   loss = 3.5280895981437714
06/29 07:40:15 AM   rep_loss = 0.8614334797790384
06/29 07:40:15 AM ***** Save model *****
06/29 07:40:42 AM ***** Running evaluation *****
06/29 07:40:42 AM   Epoch = 3 iter 38399 step
06/29 07:40:42 AM   Num examples = 9815
06/29 07:40:42 AM   Batch size = 32
06/29 07:40:42 AM ***** Eval results *****
06/29 07:40:42 AM   att_loss = 2.6619274780097855
06/29 07:40:42 AM   cls_loss = 0.0
06/29 07:40:42 AM   global_step = 38399
06/29 07:40:42 AM   loss = 3.5229836469339992
06/29 07:40:42 AM   rep_loss = 0.8610561724944794
06/29 07:40:42 AM ***** Save model *****
06/29 07:41:08 AM ***** Running evaluation *****
06/29 07:41:08 AM   Epoch = 3 iter 38599 step
06/29 07:41:08 AM   Num examples = 9815
06/29 07:41:08 AM   Batch size = 32
06/29 07:41:08 AM ***** Eval results *****
06/29 07:41:08 AM   att_loss = 2.6615449256886294
06/29 07:41:08 AM   cls_loss = 0.0
06/29 07:41:08 AM   global_step = 38599
06/29 07:41:08 AM   loss = 3.522475902871349
06/29 07:41:08 AM   rep_loss = 0.8609309810206445
06/29 07:41:08 AM ***** Save model *****
06/29 07:41:36 AM ***** Running evaluation *****
06/29 07:41:36 AM   Epoch = 3 iter 38799 step
06/29 07:41:36 AM   Num examples = 9815
06/29 07:41:36 AM   Batch size = 32
06/29 07:41:36 AM ***** Eval results *****
06/29 07:41:36 AM   att_loss = 2.6613635450211417
06/29 07:41:36 AM   cls_loss = 0.0
06/29 07:41:36 AM   global_step = 38799
06/29 07:41:36 AM   loss = 3.5221260781254533
06/29 07:41:36 AM   rep_loss = 0.8607625364657014
06/29 07:41:36 AM ***** Save model *****
06/29 07:42:02 AM ***** Running evaluation *****
06/29 07:42:02 AM   Epoch = 3 iter 38999 step
06/29 07:42:02 AM   Num examples = 9815
06/29 07:42:02 AM   Batch size = 32
06/29 07:42:02 AM ***** Eval results *****
06/29 07:42:02 AM   att_loss = 2.6598886361606384
06/29 07:42:02 AM   cls_loss = 0.0
06/29 07:42:02 AM   global_step = 38999
06/29 07:42:02 AM   loss = 3.520474043114951
06/29 07:42:02 AM   rep_loss = 0.8605854100899639
06/29 07:42:02 AM ***** Save model *****
06/29 07:42:28 AM ***** Running evaluation *****
06/29 07:42:28 AM   Epoch = 3 iter 39199 step
06/29 07:42:28 AM   Num examples = 9815
06/29 07:42:28 AM   Batch size = 32
06/29 07:42:28 AM ***** Eval results *****
06/29 07:42:28 AM   att_loss = 2.6572778602158036
06/29 07:42:28 AM   cls_loss = 0.0
06/29 07:42:28 AM   global_step = 39199
06/29 07:42:28 AM   loss = 3.5175193212457994
06/29 07:42:28 AM   rep_loss = 0.860241463877829
06/29 07:42:28 AM ***** Save model *****
06/29 07:42:56 AM ***** Running evaluation *****
06/29 07:42:56 AM   Epoch = 3 iter 39399 step
06/29 07:42:56 AM   Num examples = 9815
06/29 07:42:56 AM   Batch size = 32
06/29 07:42:56 AM ***** Eval results *****
06/29 07:42:56 AM   att_loss = 2.6571630437246885
06/29 07:42:56 AM   cls_loss = 0.0
06/29 07:42:56 AM   global_step = 39399
06/29 07:42:56 AM   loss = 3.5173420639620763
06/29 07:42:56 AM   rep_loss = 0.8601790223809425
06/29 07:42:56 AM ***** Save model *****
06/29 07:43:23 AM ***** Running evaluation *****
06/29 07:43:23 AM   Epoch = 3 iter 39599 step
06/29 07:43:23 AM   Num examples = 9815
06/29 07:43:23 AM   Batch size = 32
06/29 07:43:23 AM ***** Eval results *****
06/29 07:43:23 AM   att_loss = 2.653635240978931
06/29 07:43:23 AM   cls_loss = 0.0
06/29 07:43:23 AM   global_step = 39599
06/29 07:43:23 AM   loss = 3.5133961634249116
06/29 07:43:23 AM   rep_loss = 0.859760924521232
06/29 07:43:23 AM ***** Save model *****
06/29 07:43:49 AM ***** Running evaluation *****
06/29 07:43:49 AM   Epoch = 3 iter 39799 step
06/29 07:43:49 AM   Num examples = 9815
06/29 07:43:49 AM   Batch size = 32
06/29 07:43:49 AM ***** Eval results *****
06/29 07:43:49 AM   att_loss = 2.654483974738482
06/29 07:43:49 AM   cls_loss = 0.0
06/29 07:43:49 AM   global_step = 39799
06/29 07:43:49 AM   loss = 3.5143011722162276
06/29 07:43:49 AM   rep_loss = 0.8598171994339597
06/29 07:43:49 AM ***** Save model *****
06/29 07:44:15 AM ***** Running evaluation *****
06/29 07:44:15 AM   Epoch = 3 iter 39999 step
06/29 07:44:15 AM   Num examples = 9815
06/29 07:44:15 AM   Batch size = 32
06/29 07:44:15 AM ***** Eval results *****
06/29 07:44:15 AM   att_loss = 2.6566296005054455
06/29 07:44:15 AM   cls_loss = 0.0
06/29 07:44:15 AM   global_step = 39999
06/29 07:44:15 AM   loss = 3.5164864797376643
06/29 07:44:15 AM   rep_loss = 0.8598568810469238
06/29 07:44:15 AM ***** Save model *****
06/29 07:44:42 AM ***** Running evaluation *****
06/29 07:44:42 AM   Epoch = 3 iter 40199 step
06/29 07:44:42 AM   Num examples = 9815
06/29 07:44:42 AM   Batch size = 32
06/29 07:44:42 AM ***** Eval results *****
06/29 07:44:42 AM   att_loss = 2.6583502829532546
06/29 07:44:42 AM   cls_loss = 0.0
06/29 07:44:42 AM   global_step = 40199
06/29 07:44:42 AM   loss = 3.5182257552014535
06/29 07:44:42 AM   rep_loss = 0.8598754735684437
06/29 07:44:42 AM ***** Save model *****
06/29 07:45:11 AM ***** Running evaluation *****
06/29 07:45:11 AM   Epoch = 3 iter 40399 step
06/29 07:45:11 AM   Num examples = 9815
06/29 07:45:11 AM   Batch size = 32
06/29 07:45:11 AM ***** Eval results *****
06/29 07:45:11 AM   att_loss = 2.6568091870085593
06/29 07:45:11 AM   cls_loss = 0.0
06/29 07:45:11 AM   global_step = 40399
06/29 07:45:11 AM   loss = 3.516472292159166
06/29 07:45:11 AM   rep_loss = 0.8596631072781569
06/29 07:45:11 AM ***** Save model *****
06/29 07:45:37 AM ***** Running evaluation *****
06/29 07:45:37 AM   Epoch = 3 iter 40599 step
06/29 07:45:37 AM   Num examples = 9815
06/29 07:45:37 AM   Batch size = 32
06/29 07:45:37 AM ***** Eval results *****
06/29 07:45:37 AM   att_loss = 2.6565984621352765
06/29 07:45:37 AM   cls_loss = 0.0
06/29 07:45:37 AM   global_step = 40599
06/29 07:45:37 AM   loss = 3.5161141020497255
06/29 07:45:37 AM   rep_loss = 0.8595156425593458
06/29 07:45:37 AM ***** Save model *****
06/29 07:46:03 AM ***** Running evaluation *****
06/29 07:46:03 AM   Epoch = 3 iter 40799 step
06/29 07:46:03 AM   Num examples = 9815
06/29 07:46:03 AM   Batch size = 32
06/29 07:46:03 AM ***** Eval results *****
06/29 07:46:03 AM   att_loss = 2.656809686268626
06/29 07:46:03 AM   cls_loss = 0.0
06/29 07:46:03 AM   global_step = 40799
06/29 07:46:03 AM   loss = 3.5162501702401965
06/29 07:46:03 AM   rep_loss = 0.8594404864239441
06/29 07:46:03 AM ***** Save model *****
06/29 07:46:32 AM ***** Running evaluation *****
06/29 07:46:32 AM   Epoch = 3 iter 40999 step
06/29 07:46:32 AM   Num examples = 9815
06/29 07:46:32 AM   Batch size = 32
06/29 07:46:32 AM ***** Eval results *****
06/29 07:46:32 AM   att_loss = 2.6540191008095757
06/29 07:46:32 AM   cls_loss = 0.0
06/29 07:46:32 AM   global_step = 40999
06/29 07:46:32 AM   loss = 3.5131343799632986
06/29 07:46:32 AM   rep_loss = 0.8591152808908863
06/29 07:46:32 AM ***** Save model *****
06/29 07:46:58 AM ***** Running evaluation *****
06/29 07:46:58 AM   Epoch = 3 iter 41199 step
06/29 07:46:58 AM   Num examples = 9815
06/29 07:46:58 AM   Batch size = 32
06/29 07:46:58 AM ***** Eval results *****
06/29 07:46:58 AM   att_loss = 2.6528515638796315
06/29 07:46:58 AM   cls_loss = 0.0
06/29 07:46:58 AM   global_step = 41199
06/29 07:46:58 AM   loss = 3.511765676277498
06/29 07:46:58 AM   rep_loss = 0.8589141139878674
06/29 07:46:58 AM ***** Save model *****
06/29 07:47:24 AM ***** Running evaluation *****
06/29 07:47:24 AM   Epoch = 3 iter 41399 step
06/29 07:47:24 AM   Num examples = 9815
06/29 07:47:24 AM   Batch size = 32
06/29 07:47:24 AM ***** Eval results *****
06/29 07:47:24 AM   att_loss = 2.6519608489561435
06/29 07:47:24 AM   cls_loss = 0.0
06/29 07:47:24 AM   global_step = 41399
06/29 07:47:24 AM   loss = 3.510659587263697
06/29 07:47:24 AM   rep_loss = 0.8586987399711808
06/29 07:47:24 AM ***** Save model *****
