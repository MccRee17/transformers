Experiment dir : ./results/base/base-resnet20
args = Namespace(batch_size=64, cuda=1, data_name='cifar10', epochs=200, img_root='./datasets', lr=0.001, momentum=0.9, net_name='resnet20', note='base-resnet20', num_class=10, print_freq=50, save_root='./results/base/base-resnet20', seed=2, softmax_relu=False, weight_decay=0.0001)
unparsed_args = []
----------- Network Initialization --------------
DataParallel(
  (module): resnet20(
    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (res1): Sequential(
      (0): resblock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): resblock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): resblock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (res2): Sequential(
      (0): resblock(
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (ds): Sequential(
          (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): resblock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (2): resblock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (avgpool): AvgPool2d(kernel_size=8, stride=8, padding=0)
    (fc): Linear(in_features=128, out_features=10, bias=True)
  )
)
param size = 0.067418MB
-----------------------------------------------
Saving initial parameters......
Files already downloaded and verified
Files already downloaded and verified
Epoch: 1  lr: 0.001
Epoch[1]:[050/782] Time:0.0122 Data:0.0001  loss:2.2823(2.4196)  prec@1:10.94(9.91)  prec@5:60.94(49.69)
Epoch[1]:[100/782] Time:0.0123 Data:0.0001  loss:2.3007(2.3872)  prec@1:4.69(9.55)  prec@5:48.44(48.81)
Epoch[1]:[150/782] Time:0.0125 Data:0.0001  loss:2.2797(2.3714)  prec@1:14.06(9.80)  prec@5:53.12(49.38)
Epoch[1]:[200/782] Time:0.0123 Data:0.0001  loss:2.4489(2.3608)  prec@1:9.38(9.84)  prec@5:35.94(49.53)
Epoch[1]:[250/782] Time:0.0122 Data:0.0001  loss:2.2987(2.3531)  prec@1:7.81(10.06)  prec@5:60.94(49.86)
Epoch[1]:[300/782] Time:0.0124 Data:0.0001  loss:2.3580(2.3478)  prec@1:7.81(10.12)  prec@5:53.12(50.07)
Epoch[1]:[350/782] Time:0.0121 Data:0.0001  loss:2.3007(2.3441)  prec@1:10.94(10.20)  prec@5:45.31(50.14)
Epoch[1]:[400/782] Time:0.0123 Data:0.0001  loss:2.2921(2.3416)  prec@1:10.94(10.23)  prec@5:53.12(50.36)
Epoch[1]:[450/782] Time:0.0123 Data:0.0001  loss:2.3304(2.3393)  prec@1:14.06(10.18)  prec@5:53.12(50.34)
Epoch[1]:[500/782] Time:0.0122 Data:0.0001  loss:2.3263(2.3372)  prec@1:7.81(10.14)  prec@5:59.38(50.23)
Epoch[1]:[550/782] Time:0.0121 Data:0.0001  loss:2.3216(2.3358)  prec@1:10.94(10.20)  prec@5:51.56(50.24)
Epoch[1]:[600/782] Time:0.0123 Data:0.0001  loss:2.2873(2.3347)  prec@1:18.75(10.16)  prec@5:53.12(50.26)
Epoch[1]:[650/782] Time:0.0122 Data:0.0001  loss:2.3761(2.3336)  prec@1:7.81(10.12)  prec@5:39.06(50.17)
